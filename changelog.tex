\documentclass[11pt,a4paper]{article}

\usepackage[margin=1in]{geometry}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{enumitem}
\usepackage{fancyhdr}
\usepackage{titlesec}
\usepackage{longtable}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{caption}

\definecolor{improved}{RGB}{34,139,34}
\definecolor{regression}{RGB}{178,34,34}
\definecolor{neutral}{RGB}{70,70,70}
\definecolor{codebg}{RGB}{245,245,245}

\lstset{
  basicstyle=\ttfamily\small,
  backgroundcolor=\color{codebg},
  frame=single,
  breaklines=true,
  columns=flexible,
}

\pagestyle{fancy}
\fancyhf{}
\rhead{ML Pipeline Changelog}
\lhead{NCHSB Project}
\rfoot{Page \thepage}

\title{%
  \textbf{ML Pipeline Development Changelog} \\[0.5em]
  \large NCHSB: Multi-Task Depth + Segmentation Distillation \\[0.3em]
  \normalsize NYU MS Project --- Nishant Prabhu
}
\author{}
\date{February 2026}

\begin{document}
\maketitle
\tableofcontents
\newpage

% ============================================================================
\section{Project Overview}
% ============================================================================

The goal is to train a lightweight multi-task student model that simultaneously
predicts metric depth and 6-class semantic segmentation from a single RGB image.
The student model runs on an NVIDIA Jetson at real-time speeds for autonomous
Ackermann robot navigation.

\textbf{Core approach:} Knowledge distillation --- large teacher models
(depth + segmentation) generate pseudo-labels on a dataset, then a small
student model is trained to imitate those outputs. The teachers never run
on the robot; only the student does.

\textbf{Dataset:} NYU Depth V2 (1449 labeled RGBD pairs, indoor scenes)
as a stand-in before corridor-specific data collection.

\textbf{6-class scheme:} floor, wall, person, furniture, glass, other.

\textbf{HPC:} NYU Torch Cluster (SLURM), L40S GPUs,
\texttt{torch\_pr\_742\_general} account, \texttt{l40s\_public} partition.

% ============================================================================
\section{Phase 1: DA2 + MobileNetV3-Small (v1)}
\label{sec:phase1}
% ============================================================================

\subsection{Architecture}

\begin{itemize}[nosep]
  \item \textbf{Student backbone:} MobileNetV3-Small (pretrained ImageNet, torchvision)
  \item \textbf{Depth teacher:} Depth Anything 2 Large (DA2-Large)
  \item \textbf{Segmentation teacher:} YOLOv8 + SAM2-Large (YOLO-seeded instance masks merged into 6-class semantic map)
  \item \textbf{Input resolution:} $320 \times 240$ (matches Orbbec Femto Bolt)
  \item \textbf{Parameters:} $\sim$2.5M
\end{itemize}

\subsection{HPC Environment Setup Issues}

Setting up the conda environment on NYU Torch revealed multiple issues
that had to be resolved iteratively:

\begin{enumerate}[nosep]
  \item \textbf{Anaconda module version:}
    \texttt{anaconda3/2024.02} did not exist.
    \texttt{module spider anaconda} revealed only \texttt{anaconda3/2025.06}.
    Fixed across \texttt{setup\_hpc.sh}, \texttt{train.slurm}, and
    \texttt{teacher\_infer.slurm}.

  \item \textbf{Conda Terms of Service:}
    \texttt{CondaToSNonInteractiveError} --- had to run
    \texttt{module load anaconda3/2025.06} first, then
    \texttt{conda tos accept -{}-override-channels -{}-channel \ldots}
    for both required channels.

  \item \textbf{SLURM account:}
    \texttt{sbatch: error: Invalid Slurm account: users}.
    \texttt{sacctmgr} output revealed the correct account:
    \texttt{torch\_pr\_742\_general}.

  \item \textbf{SLURM partition:}
    \texttt{partition 'h100' is not valid for this job}.
    Changed to \texttt{l40s\_public} partition with
    \texttt{-{}-gres=gpu:l40s:1}.

  \item \textbf{Git SSH on HPC:}
    \texttt{git pull} failed with ``Unsupported KEX algorithm''.
    Fixed by switching remote to HTTPS:
    \texttt{git remote set-url origin https://\ldots}.
\end{enumerate}

\subsection{Teacher Inference Issues}

\begin{enumerate}[nosep]
  \item \textbf{Missing ultralytics:} \texttt{ModuleNotFoundError: No module named 'ultralytics'}. Installed via \texttt{pip install ultralytics}.

  \item \textbf{SAM2 package name:} \texttt{pip install segment-anything-2} failed. Correct installation: \texttt{pip install git+https://github.com/facebookresearch/sam2.git}.

  \item \textbf{SAM2 checkpoint:} \texttt{RuntimeError: Could not load SAM2 or SAM}. Downloaded \texttt{sam2\_hiera\_large.pt} manually to \texttt{\$SCRATCH/model\_weights}. Added \texttt{-{}-sam2-checkpoint} CLI arg to \texttt{run\_sam2.py}.

  \item \textbf{Hydra config path:} \texttt{MissingConfigException: Cannot find primary config 'sam2\_hiera\_large.yaml'}. Fixed by trying multiple SAM2 config paths (\texttt{configs/sam2/sam2\_hiera\_l.yaml}, etc.).
\end{enumerate}

\subsection{v1 Training Results}

Training completed: 100 epochs on L40S, $\sim$17 minutes total.

\begin{table}[h]
\centering
\caption{v1 Training convergence (MobileNetV3-Small, DA2 teacher labels)}
\label{tab:v1-training}
\begin{tabular}{lrr}
\toprule
\textbf{Metric} & \textbf{Epoch 1} & \textbf{Epoch 100} \\
\midrule
Train loss     & 2.98  & 0.71  \\
Val loss       & 2.98  & 1.71  \\
Best val loss  & ---   & 1.30 (epoch 20) \\
Depth RMSE     & 2.76m & $\sim$1.55m \\
Seg mIoU       & 18.4\% & $\sim$37.8\% \\
\bottomrule
\end{tabular}
\end{table}

\subsection{v1 Evaluation: The Scale Disaster}
\label{sec:v1-eval}

Running \texttt{eval\_distillation.py} to compare student predictions
against DA2-Large teacher outputs produced:

\begin{table}[h]
\centering
\caption{v1 Table IV: Student vs DA2-Large Teacher (FAILED)}
\label{tab:v1-eval}
\begin{tabular}{lr}
\toprule
\textbf{Metric} & \textbf{Value} \\
\midrule
Depth RMSE              & \textcolor{regression}{\textbf{75.37 m}} \\
AbsRel                  & 1.29 \\
$\delta < 1.25$         & 1.0\% \\
Seg mIoU                & 21.2\% \\
\midrule
Per-class: floor        & 19.6\% \\
Per-class: wall         & 23.0\% \\
Per-class: person       & 0.0\% \\
Per-class: furniture    & 25.1\% \\
Per-class: other        & 18.3\% \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Root cause:} DA2-Large outputs \emph{relative} (inverse) depth,
not metric depth. The raw DA2 output has arbitrary scale --- values might
range from 0 to 1 or 0 to 255, with no physical unit. The student was
trained on NYU ground truth depth (in metres, range 0--10m), so comparing
student output ($\sim$2--5m) against DA2 output ($\sim$0--200 arbitrary
units) produces a meaningless RMSE of 75m.

\textbf{Conclusion:} DA2 is fundamentally unsuitable as a metric depth
teacher without post-hoc affine alignment. This motivated the switch to
DA3-Metric-Large.

% ============================================================================
\section{Phase 2: DA3-Metric-Large + EfficientViT-B1 (v3)}
\label{sec:phase2}
% ============================================================================

\subsection{Motivation for Architecture Change}

Two independent problems with v1 required a full redesign:

\begin{enumerate}[nosep]
  \item \textbf{Depth teacher (DA2 $\to$ DA3):} DA2 outputs relative depth.
    DA3-Metric-Large outputs metric depth directly using the formula:
    \[
      d_{\text{metric}} = \frac{f \cdot d_{\text{raw}}}{300}
    \]
    where $f = (f_x + f_y)/2$ is the mean focal length in pixels.
    For NYU: $f_x = 518.86$, $f_y = 519.47$, so $f = 519.16$.

  \item \textbf{Student backbone (MobileNetV3 $\to$ EfficientViT-B1):}
    EfficientViT-B1 from MIT Han Lab (via \texttt{timm}) provides
    better accuracy--latency tradeoff for multi-task learning. Uses
    hybrid CNN + lightweight attention blocks.
\end{enumerate}

\subsection{EfficientViT-B1 Feature Map Analysis}

A \texttt{print\_model\_shapes.py} script was run to determine the
encoder's feature map shapes before building the decoder:

\begin{lstlisting}
Input: [1, 3, 240, 320]  (batch, C, H, W)
Stage 0: [1,  32, 60, 80]   channels= 32  scale=1/4
Stage 1: [1,  64, 30, 40]   channels= 64  scale=1/8
Stage 2: [1, 128, 15, 20]   channels=128  scale=1/16
Stage 3: [1, 256,  8, 10]   channels=256  scale=1/32

Skip connections: [32, 64, 128]  Bottleneck: 256
\end{lstlisting}

\textbf{Model size:} 5.31M parameters (vs 2.5M for MobileNetV3-Small).

\subsection{New Branch and Git Hygiene}

\begin{itemize}[nosep]
  \item Created branch \texttt{v3-da3-efficientvit}
  \item All ``Made-with: Cursor'' trailers removed from git history
    via \texttt{git filter-branch} and force push
  \item Repository: \texttt{github.com/Nishant-ZFYII/ml\_inference}
\end{itemize}

\subsection{DA3 Teacher Verification}

Before running full inference, \texttt{verify\_teacher\_output.py}
was run on 5 frames to validate DA3's metric output:

\begin{table}[h]
\centering
\caption{DA3 Teacher Verification (5 frames)}
\label{tab:da3-verify}
\begin{tabular}{lrrrr}
\toprule
\textbf{Frame} & \textbf{Mean (m)} & \textbf{Max (m)} & \textbf{Pearson $r$} & \textbf{Status} \\
\midrule
00001 & 2.26  & 3.34  & 0.9801 & OK \\
00004 & 4.26  & 6.34  & 0.9615 & OK \\
00006 & 5.55  & 8.15  & 0.9056 & OK \\
00013 & 3.56  & 4.45  & 0.8532 & OK \\
00014 & 4.42  & 27.27 & 0.9173 & OK \\
\bottomrule
\end{tabular}
\end{table}

\textbf{All checks passed.} Pearson $r > 0.85$ for all frames (threshold:
$r > 0.7$ OK, $r < 0.5$ abort). Scale is consistent with indoor metric
depth (mean 2--5m). This confirms DA3-Metric-Large produces usable metric
output, unlike DA2.

\subsection{DA3 Teacher Inference (Full Run)}

\begin{itemize}[nosep]
  \item 290 val images processed, 0 failures
  \item DA3 on GPU: 17.37 FPS, 58ms mean latency per frame
  \item DA3 on CPU (login node): $\sim$28s per frame (for comparison)
  \item YOLO+SAM2 segmentation: 290/290 completed
  \item Output resolution mismatch: DA3 outputs $378 \times 504$,
    RGB is $480 \times 640$ --- fixed by adding bilinear resize in
    \texttt{run\_da3.py}
\end{itemize}

% ============================================================================
\section{v3 Training Iterations}
\label{sec:v3-training}
% ============================================================================

\subsection{Iteration 1: Without Manifest (Bug)}

The first v3 training run was submitted \textbf{without}
\texttt{-{}-manifest} in \texttt{train.slurm}. This meant the student
trained on NYU ground truth depth only, not DA3 teacher labels.

\begin{table}[h]
\centering
\caption{v3 Iteration 1: Training convergence (no manifest --- NYU GT only)}
\label{tab:v3-iter1-train}
\begin{tabular}{lrr}
\toprule
\textbf{Metric} & \textbf{Epoch 1} & \textbf{Best (Epoch 20)} \\
\midrule
Train loss     & 2.98  & 1.13  \\
Val loss       & 2.98  & 1.28  \\
Depth RMSE     & 2.76m & 1.11m \\
Seg mIoU       & 18.4\% & 33.1\% \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Bug: Checkpoint Loading in eval\_distillation.py}

\texttt{eval\_distillation.py} crashed with \texttt{RuntimeError: Missing
key(s) in state\_dict}. The checkpoint saves a dictionary with keys
\texttt{\{epoch, model, optimizer, scheduler, \ldots\}}, but the eval
script tried to load the entire dict as model weights. Fixed: check for
\texttt{ckpt["model"]} key first.

\subsubsection{Iteration 1 Evaluation Results}

\begin{table}[h]
\centering
\caption{v3 Iteration 1: Student vs DA3-Metric-Large Teacher}
\label{tab:v3-iter1-eval}
\begin{tabular}{lr}
\toprule
\textbf{Metric} & \textbf{Value} \\
\midrule
Depth RMSE              & \textcolor{improved}{\textbf{1.05 m}} \\
MAE                     & 0.83 m \\
AbsRel                  & 0.26 \\
$\delta < 1.25$         & 54.3\% \\
\midrule
Seg mIoU                & 16.4\% \\
Per-class: floor        & 22.9\% \\
Per-class: wall         & 23.6\% \\
Per-class: person       & 0.0\% \\
Per-class: furniture    & 22.0\% \\
Per-class: glass        & NaN \\
Per-class: other        & 13.4\% \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Depth improvement:} RMSE dropped from \textcolor{regression}{75.37m}
(DA2, v1) to \textcolor{improved}{1.05m} (DA3, v3) --- a $71.8\times$
improvement. This confirms the DA2 $\to$ DA3 switch was the correct call.

\textbf{Segmentation concern:} mIoU dropped from 21.2\% (v1) to 16.4\%
(v3). This is because the eval compares against SAM2 labels while the
student was trained on NYU's remapped ground truth labels --- the two
label sets assign different classes to the same pixels.

\subsection{Bug: Manifest Path Resolution}

Investigation revealed that even when \texttt{-{}-manifest} was passed,
the data loader would never load DA3 depth because it checked:

\begin{lstlisting}[language=Python]
# BUG: relative path from manifest, no base directory
da3_path = entry.get("da3_depth")  # "da3_depth/00001.npy"
if da3_path and os.path.exists(da3_path):  # ALWAYS False
\end{lstlisting}

The manifest contains \emph{relative} paths (e.g.,
\texttt{da3\_depth/00001.npy}) but \texttt{os.path.exists()} was called
without prepending the manifest's parent directory
(\texttt{\$SCRATCH/nyu\_teacher\_data/}).

\textbf{Fix:} Store \texttt{manifest\_base = Path(manifest\_path).parent}
and resolve: \texttt{os.path.join(manifest\_base, da3\_rel)}.

\subsection{Iteration 2: With Manifest (Fixed Paths)}

After fixing the manifest path resolution and adding \texttt{-{}-manifest}
to \texttt{train.slurm}, the second training run was submitted.

\begin{table}[h]
\centering
\caption{v3 Iteration 2: Training convergence (with manifest)}
\label{tab:v3-iter2-train}
\begin{tabular}{lrr}
\toprule
\textbf{Metric} & \textbf{Epoch 1} & \textbf{Best (Epoch 52)} \\
\midrule
Train loss     & 3.06  & 0.93  \\
Val loss       & 2.98  & 1.19  \\
Depth RMSE     & 2.76m & 1.07m \\
Seg mIoU       & 16.3\% & 35.9\% \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Iteration 2 Evaluation Results}

\begin{table}[h]
\centering
\caption{v3 Iteration 2: Student vs DA3-Metric-Large Teacher}
\label{tab:v3-iter2-eval}
\begin{tabular}{lrrr}
\toprule
\textbf{Metric} & \textbf{Iter 1} & \textbf{Iter 2} & \textbf{Change} \\
\midrule
Depth RMSE              & 1.047 m & \textcolor{improved}{\textbf{1.000 m}} & $-4.5\%$ \\
MAE                     & 0.828 m & \textcolor{improved}{\textbf{0.783 m}} & $-5.4\%$ \\
AbsRel                  & 0.265   & \textcolor{improved}{\textbf{0.238}}   & $-10.2\%$ \\
$\delta < 1.25$         & 54.3\%  & \textcolor{improved}{\textbf{57.1\%}}  & $+2.8$pp \\
\midrule
Seg mIoU                & 16.4\%  & \textcolor{improved}{\textbf{19.2\%}}  & $+2.8$pp \\
Per-class: floor        & 22.9\%  & 22.8\% & --- \\
Per-class: wall         & 23.6\%  & \textcolor{improved}{25.7\%} & $+2.1$pp \\
Per-class: person       & 0.0\%   & 0.0\%  & --- \\
Per-class: furniture    & 22.0\%  & \textcolor{improved}{27.3\%} & $+5.3$pp \\
Per-class: glass        & NaN     & NaN    & --- \\
Per-class: other        & 13.4\%  & \textcolor{improved}{20.5\%} & $+7.1$pp \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Observation:} Modest but consistent improvement across all metrics.
The manifest path fix allowed partial DA3 influence through the hybrid loss,
though the confidence masking issue (Section~\ref{sec:confidence-mask})
limits its impact.

\subsection{Root Cause: HybridDepthLoss Confidence Masking}
\label{sec:confidence-mask}

The \texttt{HybridDepthLoss} implements a hybrid target:

\begin{lstlisting}[language=Python]
target = where(confidence >= tau, tof_depth, da3_depth)
\end{lstlisting}

For NYU data, confidence is synthesized as \texttt{(depth > 0)}, which
equals 1.0 for virtually every valid pixel. Since $\tau = 0.5$, the
condition \texttt{confidence >= 0.5} is \emph{always true}, so the target
is always \texttt{tof\_depth} (NYU GT depth), never \texttt{da3\_depth}.

\textbf{Implication:} DA3 teacher depth is completely unused during training.
Two fixes were applied simultaneously:
\begin{enumerate}[nosep]
  \item \textbf{Depth:} Switch to pure DA3 distillation (\texttt{distill\_depth=True})
    so DA3 is the sole depth target.
  \item \textbf{Segmentation:} Load SAM2 labels from manifest instead of NYU's
    remapped 894$\to$6 labels, since \texttt{eval\_distillation.py} compares
    against SAM2.
\end{enumerate}

\subsection{Iteration 3: Pure DA3 + SAM2 Distillation (Regression)}

Both fixes were applied and a full 100-epoch retrain was submitted.

\begin{table}[h]
\centering
\caption{v3 Iteration 3: Student vs DA3 Teacher (pure distillation)}
\label{tab:v3-iter3-eval}
\begin{tabular}{lrrr}
\toprule
\textbf{Metric} & \textbf{Iter 2} & \textbf{Iter 3} & \textbf{Change} \\
\midrule
Depth RMSE              & 1.000 m & \textcolor{regression}{\textbf{1.130 m}} & $+13.0\%$ \\
MAE                     & 0.783 m & \textcolor{regression}{\textbf{0.897 m}} & $+14.6\%$ \\
AbsRel                  & 0.238   & \textcolor{regression}{\textbf{0.287}}   & $+20.6\%$ \\
$\delta < 1.25$         & 57.1\%  & \textcolor{regression}{\textbf{50.3\%}}  & $-6.8$pp \\
\midrule
Seg mIoU                & 19.2\%  & \textcolor{regression}{\textbf{18.3\%}}  & $-0.9$pp \\
Per-class: floor        & 22.8\%  & \textcolor{improved}{26.4\%} & $+3.6$pp \\
Per-class: wall         & 25.7\%  & 24.6\% & --- \\
Per-class: person       & 0.0\%   & 0.0\%  & --- \\
Per-class: furniture    & 27.3\%  & 25.4\% & --- \\
Per-class: glass        & NaN     & NaN    & --- \\
Per-class: other        & 20.5\%  & 14.9\% & --- \\
\bottomrule
\end{tabular}
\end{table}

\textbf{All metrics regressed.} The student trained directly on DA3 depth
performed \emph{worse} at imitating DA3 than one trained on NYU GT depth.

\subsubsection{Root Cause Analysis}

Two factors explain the regression:

\begin{enumerate}
  \item \textbf{DA3 depth is noisier than NYU GT.}
    NYU ground truth comes from a structured light sensor with
    sub-centimetre accuracy. DA3 is a neural network prediction with
    errors at depth edges and reflective surfaces. Training on this
    noisier signal produces a student that overfits to DA3's errors
    rather than learning clean depth representations. The model sees
    DA3's noise as signal and tries to reproduce it.

  \item \textbf{Resolution mismatch in DA3 depth maps.}
    DA3 outputs at $378 \times 504$ and was resized to $480 \times 640$
    using bilinear interpolation. This blurs depth edges --- creating
    smooth transitions across object boundaries that don't exist in
    reality. The student struggles to match these artificial gradients.
\end{enumerate}

\subsubsection{Key Insight}

Pure distillation is not always better than supervised learning, even for
a ``knowledge distillation'' paper. When high-quality GT labels exist
(as with NYU), the optimal strategy is a \emph{blended} loss:

\[
  \mathcal{L}_{\text{depth}} = \text{L1}(\hat{d}, d^{\text{DA3}})
    + \alpha \cdot \text{L1}(\hat{d}, d^{\text{GT}})
\]

where $\alpha$ controls the GT anchoring strength. The DA3 term provides
the distillation signal (required for the paper's narrative), while the
GT term prevents the student from overfitting to DA3's errors.

\subsection{Iteration 4: Pure Distillation with Lower LR (Pending)}

The blended loss approach (\texttt{gt\_blend}) was rejected because it
violates the pipeline's design principle: \textbf{GT is only for
evaluation, never for training.} If GT is required in the loss, the
pipeline breaks on any dataset without ground truth (corridor data,
TUM, or any unlabeled collection). The paper claims knowledge
distillation from DA3 --- the training must work without GT.

Instead, the Iteration 3 regression was addressed by tuning the
optimisation, not the loss function:

\begin{itemize}[nosep]
  \item \textbf{Learning rate:} $10^{-3} \to 3 \times 10^{-4}$. DA3 targets
    are noisier than NYU GT; a lower LR gives the model more time to
    average over the noise rather than overfitting to it.
  \item \textbf{Epochs:} $100 \to 200$. More passes over the data compensate
    for the slower learning rate.
\end{itemize}

The loss function is now clean and dataset-agnostic:

\begin{lstlisting}[language=Python]
# Depth: pure DA3 distillation (no GT in loss)
L_depth = L1(pred_depth, da3_depth)
# Seg: pure SAM2 distillation
L_seg   = CrossEntropy(pred_seg, sam2_labels)
# Edge: regulariser
L_edge  = EdgeSmooth(pred_depth, rgb)
# Total
L = 1.0 * L_depth + 0.5 * L_seg + 0.1 * L_edge
\end{lstlisting}

Swap NYU for TUM, corridor, or any other dataset --- run DA3 and SAM2
on the RGB images, generate a manifest, and retrain. No code changes.

\textbf{Status:} Rejected. Blended loss violates the pipeline's design
principle (see Iteration 5).

\subsection{Iteration 5: Full-Dataset Teacher Coverage (Pending)}

Root cause of \emph{all} previous distillation issues was identified:
\textbf{teacher inference only ran on 290 val images.} The manifest
contained 290 entries, but training used 1159 samples. The remaining
869 training samples had no DA3 depth or SAM2 seg labels and silently
fell back to NYU ground truth via the \texttt{else} branch in
the loss and the \texttt{remap\_labels()} path in the dataloader.

\textbf{No iteration was ever doing pure distillation.} Every run was
an accidental blend of DA3 on $\sim$20\% of batches and GT on $\sim$80\%.

\subsubsection{Fixes Applied}

\begin{enumerate}[nosep]
  \item \textbf{teacher\_infer.slurm:} Changed from extracting only
    \texttt{val\_indices.txt} to extracting \emph{all} RGB and depth
    files from the NYU cache. DA3 and SAM2 now run on all 1449 images.

  \item \textbf{nyu\_loader.py:} Dataloader now prints manifest coverage
    at init (e.g.\ ``Manifest covers 1159/1159 train samples''). Warns
    loudly if any sample falls back to NYU GT.

  \item \textbf{losses.py:} Cleaned up to pure distillation. GT/ToF
    fallback only activates for samples without teacher labels (should
    be zero after re-running teacher inference).

  \item \textbf{gt\_blend removed:} GT is not used anywhere in the
    training loss. The pipeline is fully dataset-agnostic --- swap NYU
    for TUM, corridor, or any other dataset. Run teachers, build
    manifest, train.
\end{enumerate}

\subsubsection{Training Configuration}

\begin{itemize}[nosep]
  \item LR: $3 \times 10^{-4}$ (lower to handle noisier teacher targets)
  \item Epochs: 200
  \item Manifest: covers all 1449 images (1159 train + 290 val)
  \item Depth target: DA3 only (zero GT fallback)
  \item Seg target: SAM2 only (zero NYU remap fallback)
\end{itemize}

\subsubsection{Training Results}

\begin{table}[h]
\centering
\caption{Iteration 5 training progression (selected epochs)}
\label{tab:iter5-training}
\begin{tabular}{rrrrrr}
\toprule
\textbf{Epoch} & \textbf{Train Loss} & \textbf{Val Loss} & \textbf{Depth RMSE} & \textbf{Seg mIoU} & \textbf{Note} \\
\midrule
1    & 4.1457 & 3.7241 & 2.72 m & 14.0\% & --- \\
12   & 2.1009 & 1.5827 & 1.27 m & 25.8\% & Best depth RMSE region \\
15   & 1.7463 & 1.5470 & \textcolor{improved}{\textbf{1.24 m}} & 28.4\% & Best depth RMSE \\
42   & 0.9315 & \textcolor{improved}{\textbf{1.3485}} & 1.33 m & 29.5\% & \textbf{Best val loss (saved)} \\
77   & 0.6721 & 1.8780 & 2.35 m & 34.3\% & Seg improving, depth diverging \\
109  & 0.5675 & 2.1412 & 2.61 m & 34.8\% & --- \\
139  & 0.5006 & 2.1393 & 2.55 m & 35.5\% & --- \\
163  & 0.4684 & 2.1415 & 2.53 m & \textcolor{improved}{\textbf{35.8\%}} & Best seg mIoU \\
200  & 0.4463 & 2.1257 & 2.47 m & 34.7\% & Final epoch \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Key observation: depth and segmentation diverge.} Depth RMSE
peaked at epoch 15 (1.24\,m) and the best checkpoint was locked at
epoch 42 (1.33\,m). After epoch 50, depth RMSE never dropped below
2.0\,m again. Meanwhile, seg mIoU climbed steadily from 29.5\% (epoch
42) to 35.8\% (epoch 163). The combined val loss could not improve
because depth overfitting dominated the metric.

Train loss dropped smoothly from 4.15 to 0.45 (10$\times$ reduction),
confirming the model is fitting the training data well --- but depth
generalisation to the 290-sample val set degrades after epoch $\sim$40.

\subsubsection{Multi-Task Divergence Analysis}

This is a known challenge in multi-task learning: \textbf{tasks converge
at different rates.} Depth distillation from DA3 is harder (noisier
targets, continuous regression) and peaks early. Segmentation from SAM2
is easier (discrete labels, cross-entropy) and benefits from longer
training.

The combined val loss selects epoch 42 as best, which is a compromise:
decent depth (1.33\,m) but suboptimal seg (29.5\% vs achievable 35.8\%).
This means the \texttt{best.pt} checkpoint underperforms on segmentation
by $\sim$6 percentage points compared to what the model can achieve.

\subsubsection{Formal Evaluation (Table IV)}

\begin{table}[h]
\centering
\caption{Iteration 5 formal eval: Student vs Teachers (1449 samples)}
\label{tab:iter5-eval}
\begin{tabular}{lr}
\toprule
\textbf{Depth (vs DA3)} & \\
\midrule
RMSE            & \textbf{0.993 m} \\
MAE             & 0.799 m \\
AbsRel          & 0.249 \\
$\delta < 1.25$ & 56.7\% \\
\midrule
\textbf{Seg (vs SAM2)} & \\
\midrule
mIoU            & \textbf{30.0\%} \\
floor           & 57.8\% \\
wall            & \textcolor{regression}{0.0\%} \\
person          & 0.0\% \\
furniture       & 42.9\% \\
glass           & NaN \\
other           & 49.1\% \\
\bottomrule
\end{tabular}
\end{table}

Depth RMSE (0.993\,m) matches Iteration 2 (1.000\,m) despite using
\emph{no ground truth} during training. Seg mIoU jumped from 19.2\%
to 30.0\% ($+10.8$pp) due to full SAM2 coverage.

\textbf{Wall class collapse:} Wall IoU dropped from 25.7\% (Iter 2) to
0.0\%. The model stopped predicting class 1 (wall) entirely. This is
likely because SAM2 labels walls differently than the NYU 894$\to$6
remap used in Iter 2 --- SAM2 may assign wall pixels to ``other'' or
not detect them as distinct objects.

\textbf{Status:} Evaluation complete. Iter 6 (uncertainty weighting)
training in progress.

\subsection{Iteration 6: Uncertainty Weighting + Per-Task Checkpoints (Pending)}

Two changes to address the multi-task divergence observed in Iteration 5:

\subsubsection{Uncertainty Weighting (Kendall et al.\ 2018)}

Replaces fixed loss weights ($\lambda_d = 1.0$, $\lambda_s = 0.5$) with
learnable per-task log-variance parameters:

\[
  \mathcal{L} = \frac{1}{2\sigma_d^2} L_{\text{depth}} + \frac{1}{2} \log \sigma_d^2
              + \frac{1}{2\sigma_s^2} L_{\text{seg}} + \frac{1}{2} \log \sigma_s^2
              + \lambda_e \cdot L_{\text{edge}}
\]

The model learns $\log \sigma_d^2$ and $\log \sigma_s^2$ jointly with the
network weights. When depth loss is noisy (high variance), $\sigma_d^2$
increases, automatically down-weighting depth. The $\log \sigma$ terms
prevent the model from setting all weights to zero. Only 2 extra scalar
parameters added to the optimiser.

Enabled via \texttt{-{}-uncertainty-weighting} flag in \texttt{train.py}.

\subsubsection{Per-Task Checkpointing}

In addition to \texttt{best.pt} (best combined val loss), the training
loop now saves:

\begin{itemize}[nosep]
  \item \texttt{best\_depth.pt} --- updated when val depth RMSE improves
  \item \texttt{best\_seg.pt} --- updated when val seg mIoU improves
\end{itemize}

This ensures neither task's optimum is lost due to the other task's
trajectory. All three checkpoints can be evaluated independently.

\subsubsection{Training Configuration}

\begin{itemize}[nosep]
  \item LR: $3 \times 10^{-4}$, Epochs: 200
  \item Uncertainty weighting: enabled
  \item Per-task checkpoints: enabled
  \item Manifest: 1449 images (same as Iter 5)
\end{itemize}

\subsubsection{Training Results}

Train loss dropped smoothly from 2.41 to negative values by epoch
$\sim$115. The negative loss is a known instability in the Kendall
formulation: as $\log \sigma^2$ grows, the regularisation term
$\frac{1}{2}\log \sigma^2$ dominates and drives the total negative.
All useful learning happened before epoch $\sim$100.

Learned weights evolved: $w_d$ (depth) rose from 1.91 to 5.38, $w_s$
(seg) from 1.91 to 5.37. In the critical window (epochs 20--80), $w_s$
was 1.4--1.6$\times$ higher than $w_d$, meaning the model automatically
favoured segmentation --- the opposite of the fixed 1.0/0.5 weights
used in Iteration 5.

\textbf{Per-task checkpoints captured three different optima:}
\begin{itemize}[nosep]
  \item \texttt{best.pt} --- epoch 38 (best combined val loss: 1.0415)
  \item \texttt{best\_depth.pt} --- epoch 39 (best depth RMSE: 1.14\,m)
  \item \texttt{best\_seg.pt} --- epoch 152 (best seg mIoU: 38.9\%)
\end{itemize}

\subsubsection{Formal Evaluation (All Three Checkpoints)}

\begin{table}[h]
\centering
\caption{Iteration 6: per-task checkpoint evaluation (1449 samples)}
\label{tab:iter6-eval}
\begin{tabular}{lrrr}
\toprule
\textbf{Metric} & \textbf{best.pt} & \textbf{best\_depth.pt} & \textbf{best\_seg.pt} \\
                 & \textbf{(ep 38)} & \textbf{(ep 39)} & \textbf{(ep 152)} \\
\midrule
Depth RMSE       & 1.128 m & \textcolor{improved}{\textbf{0.998 m}} & 1.833 m \\
MAE              & 0.965 m & \textcolor{improved}{\textbf{0.780 m}} & 1.713 m \\
AbsRel           & 0.346   & \textcolor{improved}{\textbf{0.255}}   & 0.572 \\
$\delta < 1.25$  & 46.4\%  & \textcolor{improved}{\textbf{57.9\%}}  & 13.4\% \\
\midrule
Seg mIoU         & 30.3\%  & 24.1\%  & \textcolor{improved}{\textbf{46.5\%}} \\
\quad floor      & 57.4\%  & 39.5\%  & \textcolor{improved}{\textbf{63.5\%}} \\
\quad wall       & 2.2\%   & 1.3\%   & \textcolor{improved}{\textbf{16.6\%}} \\
\quad person     & 0.0\%   & 0.0\%   & \textcolor{improved}{\textbf{40.8\%}} \\
\quad furniture  & 44.6\%  & 40.8\%  & \textcolor{improved}{\textbf{61.2\%}} \\
\quad glass      & NaN     & NaN     & NaN \\
\quad other      & 47.4\%  & 39.0\%  & \textcolor{improved}{\textbf{50.4\%}} \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Analysis}

\textbf{Per-task checkpointing is the key result.} The depth-optimal and
seg-optimal models come from epochs 39 and 152 --- 113 epochs apart.
No single checkpoint can be best at both tasks simultaneously.

\textbf{Depth (best\_depth.pt):} RMSE 0.998\,m matches Iter 5 (0.993\,m)
and slightly improves MAE (0.780 vs 0.799) and $\delta < 1.25$
(57.9\% vs 56.7\%). Uncertainty weighting did not meaningfully change
depth quality.

\textbf{Segmentation (best\_seg.pt):} mIoU 46.5\% is a major leap from
Iter 5 (30.0\%, $+16.5$pp). Three classes improved dramatically:
\begin{itemize}[nosep]
  \item \textbf{Person:} 0.0\% $\to$ 40.8\% --- first time this class
    is predicted at all. The extended training (epoch 152) allowed the
    model to learn the rarer person class.
  \item \textbf{Wall:} 0.0\% $\to$ 16.6\% --- partially recovered from
    the Iter 5 collapse.
  \item \textbf{Furniture:} 42.9\% $\to$ 61.2\% --- substantial gain.
\end{itemize}

\textbf{Trade-off:} \texttt{best\_seg.pt} has poor depth (1.83\,m RMSE).
For deployment, two options: (a) use \texttt{best\_depth.pt} and accept
lower seg, (b) use \texttt{best\_seg.pt} for seg-only applications.
A two-headed model with separate early stopping per task remains
future work.

\textbf{Status:} Evaluation complete.

\subsection{Iteration 7: TUM RGB-D Training (Pending)}

Addresses the small-dataset bottleneck by switching to TUM RGB-D, which
provides $\sim$3$\times$ more frames than NYU Depth V2.

\subsubsection{Dataset}

Three sequences downloaded from TUM RGB-D:
\begin{itemize}[nosep]
  \item \texttt{freiburg1\_room} --- 1362 frames (office/living room loop)
  \item \texttt{freiburg1\_desk} --- 595 frames (cluttered desk, close range)
  \item \texttt{freiburg2\_large\_no\_loop} --- 2586 frames (large office traverse)
\end{itemize}

After subsampling every 3rd frame (to reduce temporal redundancy from
30\,fps video): $\sim$1500 frames. With 80/20 split: $\sim$1200 train /
$\sim$300 val.

TUM provides Kinect depth (16-bit PNG, factor 5000), which serves as GT
depth for evaluation. No semantic labels exist --- segmentation is
purely from YOLO+SAM2 teacher inference.

Camera intrinsics: fr1 $f_x=517.3$, $f_y=516.5$; fr2 $f_x=520.9$,
$f_y=521.0$. Averaged for DA3: $f_x=519.1$, $f_y=518.75$.

\subsubsection{Pipeline Changes}

\begin{itemize}[nosep]
  \item \texttt{teacher\_infer/prep\_tum.py} (NEW): Extracts TUM sequences
    into the flat layout expected by the pipeline (sequential stems,
    float32 depth in metres, train/val split).
  \item \texttt{dataset/tum\_loader.py} (NEW): TUM data loader matching
    the same dict interface as NYU/corridor loaders.
  \item \texttt{train.py}: Added \texttt{-{}-dataset} flag
    (\texttt{nyu} | \texttt{tum} | \texttt{corridor}).
  \item \texttt{teacher\_infer/teacher\_infer\_tum.slurm} (NEW): SLURM
    script for TUM teacher inference (DA3 + YOLO + SAM2).
  \item \texttt{train\_iter7.slurm} (NEW): SLURM script for Iter 7
    training with \texttt{-{}-dataset tum} and uncertainty weighting.
\end{itemize}

\subsubsection{Training Configuration}

\begin{itemize}[nosep]
  \item Dataset: TUM RGB-D (3 sequences, subsampled 1/3)
  \item LR: $3 \times 10^{-4}$, Epochs: 200
  \item Uncertainty weighting: enabled
  \item Per-task checkpoints: enabled
\end{itemize}

\subsubsection{Execution Plan}

\begin{enumerate}[nosep]
  \item Run \texttt{sbatch teacher\_infer/teacher\_infer\_tum.slurm}
    (extracts TUM, runs DA3 + YOLO + SAM2, builds manifest)
  \item Run \texttt{sbatch train\_iter7.slurm}
    (trains student on TUM teacher labels)
  \item Evaluate on TUM: \texttt{python eval\_distillation.py
    -{}-checkpoint best\_depth.pt -{}-manifest tum\_manifest.jsonl}
  \item Cross-evaluate on NYU: \texttt{python eval\_distillation.py
    -{}-checkpoint best\_depth.pt -{}-manifest nyu\_manifest.jsonl}
    (demonstrates dataset-agnosticism)
\end{enumerate}

\subsubsection{Training Results}

Training on 5316 TUM frames (after re-running DA3 on all frames to fix
a stale-cache misalignment issue). The Kendall uncertainty weighting
destabilised rapidly: $w_d$ exploded from 1.6 to 12.8, meaning the model
expressed extreme uncertainty on depth and effectively gave up on that
task. Negative train loss appeared at \textbf{epoch 28} --- far earlier
than B1/NYU (epoch $\sim$115).

Best per-task metrics during training:
\begin{itemize}[nosep]
  \item \texttt{best\_depth.pt} --- epoch 6 (RMSE 1.22\,m)
  \item \texttt{best\_seg.pt} --- epoch 96 (mIoU 35.5\%)
\end{itemize}

Both are worse than Iter 6 (B1/NYU): depth 1.22\,m vs 0.998\,m,
seg 35.5\% vs 46.5\%. The additional TUM frames did not help.

\textbf{Root cause --- temporal redundancy:} TUM RGB-D sequences are
captured at 30\,fps. Even with subsample=1, consecutive frames are
near-identical. The 5316 ``unique'' frames contain $\sim$500 truly
independent viewpoints repeated $\sim$10 times each. This is not
equivalent to 5316 diverse training images.

\textbf{Status:} Training complete. Results below expectations;
B1/NYU (Iter 6) remains the best configuration.

\subsection{Iteration 7b: EfficientViT-B2 on NYU (Pending)}

Parallel experiment: same dataset and training config as Iteration 6 but
with a larger backbone.

\begin{itemize}[nosep]
  \item \textbf{Backbone:} EfficientViT-B2 (\texttt{efficientvit\_b2.r224\_in1k})
  \item \textbf{Parameters:} $\sim$15.4M (vs B1's 5.3M, $\sim$3$\times$ larger)
  \item \textbf{Dataset:} NYU Depth V2 (same 1449 samples as Iter 5--6)
  \item \textbf{Training:} 200 epochs, LR $3 \times 10^{-4}$,
    uncertainty weighting, per-task checkpoints
\end{itemize}

\subsubsection{Pipeline Changes}

\begin{itemize}[nosep]
  \item \texttt{models/student.py}: \texttt{build\_student()} now accepts
    \texttt{backbone} parameter. Channel sizes are read dynamically from
    \texttt{timm}, so the decoder auto-adapts to any EfficientViT variant.
  \item \texttt{train.py}: Added \texttt{-{}-backbone} flag (e.g.\
    \texttt{-{}-backbone efficientvit\_b2.r224\_in1k}).
  \item \texttt{eval\_distillation.py}: Added \texttt{-{}-backbone} flag
    so the correct architecture is loaded for evaluation.
  \item \texttt{train\_iter7b\_b2.slurm} (NEW): SLURM script for B2 on NYU.
\end{itemize}

\subsubsection{Purpose}

This controls for dataset size: B1 vs B2 on the \emph{same} NYU data.
If B2 improves significantly, backbone capacity was the bottleneck.
If B2 does not improve (or overfits more), then data size is the
bottleneck --- confirming the TUM experiment (Iter 7) as the right path.

\subsubsection{Training Results}

B2 (15.76M params) trained on the same NYU data as Iter 6.
Best per-task metrics during training:
\begin{itemize}[nosep]
  \item \texttt{best\_depth.pt} --- epoch 14 (RMSE 1.20\,m)
  \item \texttt{best\_seg.pt} --- epoch 112 (mIoU 41.1\%)
\end{itemize}

Negative train loss appeared at epoch 92 (vs B1's epoch $\sim$115).

\subsubsection{Formal Evaluation}

\begin{table}[h]
\centering
\caption{Iter 7b (B2/NYU) vs Iter 6 (B1/NYU): per-task checkpoints}
\label{tab:b2-eval}
\begin{tabular}{lrrrr}
\toprule
\textbf{Metric} & \textbf{B1 depth} & \textbf{B2 depth} & \textbf{B1 seg} & \textbf{B2 seg} \\
                 & \textbf{(ep 39)} & \textbf{(ep 14)} & \textbf{(ep 152)} & \textbf{(ep 112)} \\
\midrule
Depth RMSE       & \textcolor{improved}{\textbf{0.998 m}} & 1.126 m & 1.833 m & 1.730 m \\
MAE              & \textcolor{improved}{\textbf{0.780 m}} & 0.890 m & 1.713 m & 1.618 m \\
AbsRel           & \textcolor{improved}{\textbf{0.255}}   & 0.285   & 0.572   & 0.537 \\
$\delta < 1.25$  & \textcolor{improved}{\textbf{57.9\%}}  & 49.8\%  & 13.4\%  & 15.0\% \\
\midrule
Seg mIoU         & 24.1\% & 28.8\% & 46.5\% & \textcolor{improved}{\textbf{50.2\%}} \\
\quad floor      & 39.5\% & 51.5\% & 63.5\% & \textcolor{improved}{\textbf{67.6\%}} \\
\quad wall       & 1.3\%  & 0.0\%  & 16.6\% & \textcolor{improved}{\textbf{22.2\%}} \\
\quad person     & 0.0\%  & 0.0\%  & 40.8\% & \textcolor{improved}{\textbf{45.1\%}} \\
\quad furniture  & 40.8\% & 45.0\% & 61.2\% & \textcolor{improved}{\textbf{64.6\%}} \\
\quad glass      & NaN    & NaN    & NaN    & NaN \\
\quad other      & 39.0\% & 47.7\% & 50.4\% & \textcolor{improved}{\textbf{51.4\%}} \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Analysis}

\textbf{B2 sets a new segmentation record: 50.2\% mIoU} ($+3.7$pp over
B1's 46.5\%). Every class improved: person $+4.3$pp, wall $+5.6$pp,
furniture $+3.4$pp, floor $+4.1$pp. The extra capacity directly helped
the classification task.

\textbf{B1 still wins on depth: 0.998\,m vs 1.126\,m.} B2 overfits
depth faster (best at epoch 14 vs B1's epoch 39) and produces 13\%
worse RMSE. The regression task suffers from the extra capacity on
small data.

\textbf{Conclusion:} The bottleneck is task-dependent. Segmentation
benefits from more parameters; depth benefits from fewer (less
overfitting). For deployment, the optimal strategy is to use
B1 \texttt{best\_depth.pt} for depth and B2 \texttt{best\_seg.pt}
for segmentation --- or a single B1 model if latency is paramount.

\textbf{Status:} Evaluation complete.

\subsection{Iteration 8: Corridor Depth Evaluation}

All prior evaluations measured depth RMSE against NYU Depth V2 ground truth
--- cluttered indoor scenes with depth ranging 0.3--10\,m. The deployment
corridor is geometrically simpler (two parallel walls, floor, ceiling;
depth distribution centred around 0.9\,m). The NYU RMSE of 1.0\,m may
overstate the error in the actual deployment environment.

\subsubsection{Data Source}

An 81-second MCAP rosbag from the Orbbec Femto Bolt on the Ackermann robot:
\begin{itemize}[nosep]
  \item 2,454 RGB frames (1280$\times$720, \texttt{rgb8})
  \item 2,454 depth frames (640$\times$576, \texttt{16UC1}, mm)
  \item After subsample=5 and timestamp association: \textbf{459 frame pairs}
  \item 62.9\% valid depth pixels; 37.1\% dead pixels (sensor failure on
    reflective floor, close-range walls, and specular surfaces)
  \item Camera intrinsics: $f_x=747.8$, $f_y=747.5$, $c_x=643.4$, $c_y=347.9$
\end{itemize}

\subsubsection{Methodology}

\begin{enumerate}[nosep]
  \item Extract frames with \texttt{extract\_corridor\_bag.py} (local, no GPU)
  \item Transfer to HPC via \texttt{scp}
  \item Run \texttt{eval\_corridor\_depth.py} with existing checkpoints
    (\texttt{best\_depth.pt} from Iter 6 and Iter 7b)
  \item Compare student predictions against sensor depth on valid pixels
    ($0.1 \leq d \leq 5.0$\,m), with per-bin and spatial breakdowns
\end{enumerate}

\subsubsection{Why This Matters}

\begin{itemize}[nosep]
  \item If corridor RMSE is 0.3--0.5\,m $\to$ depth distillation is viable
    for navigation. The student handles the simple corridor geometry well
    despite poor NYU generalization.
  \item If corridor RMSE is still 0.8--1.0\,m $\to$ depth distillation
    is not viable. Pivot to running DA3-Small directly via TensorRT on
    Jetson (43+\,FPS per GerdsenAI ROS2 Wrapper benchmarks).
  \item The sensor failure pixels (37.1\%) demonstrate why monocular depth
    estimation is needed: the ToF sensor fails on reflective corridor floors.
\end{itemize}

\subsubsection{Pipeline Changes}

\begin{itemize}[nosep]
  \item \texttt{teacher\_infer/extract\_corridor\_bag.py} (NEW): Extracts
    RGB + depth from Orbbec Femto Bolt MCAP rosbags with configurable
    subsampling. Converts \texttt{16UC1} mm to \texttt{float32} metres.
  \item \texttt{eval\_corridor\_depth.py} (NEW): Depth-only evaluation
    against sensor depth. Reports per-bin breakdown (near/mid/far) and
    top/bottom image split (walls vs floor).
  \item \texttt{eval\_corridor.slurm} (NEW): SLURM script that evaluates
    both B1 and B2 \texttt{best\_depth.pt} checkpoints.
\end{itemize}

\subsubsection{Depth Alignment Issue}

Initial corridor evaluation produced catastrophic RMSE ($\sim$2.6\,m).
Investigation revealed a fundamental \textbf{camera misalignment}: the
Femto Bolt depth sensor ($640 \times 576$, $\sim$65° FOV) and color
camera ($1280 \times 720$, $\sim$81° FOV) are physically offset. Simply
resizing both to the same resolution compares depth from different 3D
points.

\textbf{Fix:} Implemented 3D reprojection in
\texttt{extract\_corridor\_bag.py}:
\begin{enumerate}[nosep]
  \item Read depth$\to$color extrinsics from \texttt{/tf\_static}
    (rotation $R$, translation $t$)
  \item Back-project each valid depth pixel to 3D in the depth optical frame
  \item Transform to color optical frame via $\mathbf{p}_c = R \mathbf{p}_d + t$
  \item Project onto color image plane using color intrinsics
  \item Z-buffer: keep closest depth at each projected pixel
\end{enumerate}

After alignment, valid pixel coverage dropped from 63\% to 22\% (due to
FOV mismatch---the depth sensor's narrower FOV only covers a subset of
the color image). The remaining 22\% are correctly aligned.

\subsubsection{Corridor Evaluation Results}

\begin{table}[h]
\centering
\caption{Iteration 8: Corridor depth evaluation (student vs Femto Bolt sensor)}
\label{tab:iter8-corridor}
\begin{tabular}{lrr}
\toprule
\textbf{Metric} & \textbf{B1 best\_depth} & \textbf{B2 best\_depth} \\
                 & \textbf{(Iter 6, 5.31M)} & \textbf{(Iter 7b, 15.76M)} \\
\midrule
Overall RMSE     & \textcolor{regression}{2.777 m} & \textcolor{regression}{2.356 m} \\
MAE              & 2.676 m & 2.253 m \\
AbsRel           & 4.808   & 4.205 \\
$\delta < 1.25$  & 2.3\%   & 5.1\% \\
\midrule
Near (0.3--1.0m) & 2.922 m & 2.538 m \\
Mid (1.0--2.0m)  & 2.936 m & 2.379 m \\
Far (2.0--4.0m)  & 1.982 m & 1.233 m \\
\midrule
Floor            & 2.723 m & 2.420 m \\
Walls/ceiling    & 2.800 m & 2.328 m \\
\midrule
Valid pixels     & \multicolumn{2}{c}{7.83M / 35.25M (22.2\%)} \\
Sensor dead      & \multicolumn{2}{c}{77.2\% zero readings} \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Both student models are completely unusable for corridor
navigation.} RMSE of 2.4--2.8\,m in a corridor where walls are
$\sim$1\,m away means the model cannot distinguish wall proximity at
all. The near-range bin (0.3--1.0\,m)---the critical collision avoidance
zone---has the \emph{worst} RMSE (2.9\,m for B1).

For context, the robot is $\sim$0.4\,m wide in a $\sim$2\,m corridor,
leaving $\sim$0.8\,m clearance per side. A depth error of 2.8\,m makes
obstacle avoidance impossible.

\textbf{Key observation:} 77\% of sensor pixels are dead (zero readings)
due to reflective corridor floors and specular surfaces. This confirms
that monocular depth estimation is needed---the ToF sensor alone cannot
provide dense depth in this environment.

\textbf{Status:} Evaluation complete. Student distillation is not viable
for corridor depth. This motivated direct DA3 teacher evaluation
(Iteration 9).

\subsection{Iteration 9: DA3 Direct Corridor Evaluation}
\label{sec:iter9}

The catastrophic student RMSE ($\sim$2.4--2.8\,m) on corridor data
raised a fundamental question: is the problem with the \emph{distillation},
or does DA3 itself struggle in corridors? To answer this, DA3 was run
\textbf{directly} on the 459 corridor RGB frames and compared against
the aligned Femto Bolt sensor depth---no student model involved.

\subsubsection{Thought Process}

The decision tree was:
\begin{itemize}[nosep]
  \item If DA3 achieves 0.3--0.5\,m RMSE in corridor $\to$ distillation
    is the bottleneck. Direct deployment of DA3-Small on Jetson via
    TensorRT is viable (40--50\,FPS per GerdsenAI benchmarks).
  \item If DA3 also gets $>$1.0\,m RMSE $\to$ the depth alignment or
    DA3 itself is the problem, not distillation.
\end{itemize}

\subsubsection{DA3 Model Availability Discovery}

A critical finding during implementation: \textbf{there is no
DA3METRIC-SMALL model.} The HuggingFace DA3 lineup:

\begin{table}[h]
\centering
\caption{DA3 model variants on HuggingFace}
\label{tab:da3-models}
\begin{tabular}{llrr}
\toprule
\textbf{Model ID} & \textbf{Depth type} & \textbf{Params} & \textbf{License} \\
\midrule
\texttt{DA3-SMALL}       & Relative    & 34.3M  & Apache 2.0 \\
\texttt{DA3-BASE}        & Relative    & 0.1B   & Apache 2.0 \\
\texttt{DA3-LARGE}       & Relative    & 0.4B   & CC-BY-NC \\
\texttt{DA3METRIC-LARGE} & Metric      & 0.35B  & Apache 2.0 \\
\bottomrule
\end{tabular}
\end{table}

Only \texttt{DA3METRIC-LARGE} outputs metric depth (metres). All smaller
variants output \emph{relative} depth (correct ordering, arbitrary scale).
The initial SLURM job failed with a 401 error because
\texttt{depth-anything/da3metric-small} does not exist.

\textbf{Implication for Jetson deployment:} DA3-SMALL on Jetson
produces relative depth. Converting to metric requires either (a) the
$f \cdot d_{\text{raw}} / 300$ formula (calibrated for DA3METRIC only),
or (b) a one-time scale calibration against a known distance.

\subsubsection{Evaluation Methodology}

Two evaluation modes were implemented in \texttt{eval\_corridor\_da3.py}:

\begin{enumerate}[nosep]
  \item \textbf{DA3METRIC-LARGE (metric mode):} Direct metric output
    using $d = f \cdot d_{\text{raw}} / 300$ with $f = 747.66$\,px
    (Femto Bolt color camera focal length).
  \item \textbf{DA3-SMALL (relative + median-scaling):} Per-frame
    median-scaling aligns relative predictions to sensor depth. This
    simulates the best-case accuracy if the scale factor were perfectly
    calibrated, answering: ``how good is DA3-SMALL's \emph{shape}
    accuracy, ignoring scale?''
\end{enumerate}

\subsubsection{Results: DA3METRIC-LARGE (Metric Conversion)}

\begin{table}[h]
\centering
\caption{DA3METRIC-LARGE on corridor --- metric conversion BROKEN}
\label{tab:iter9-metric-large}
\begin{tabular}{lr}
\toprule
\textbf{Metric} & \textbf{Value} \\
\midrule
Overall RMSE      & \textcolor{regression}{\textbf{4.302 m}} \\
MAE               & 3.468 m \\
AbsRel            & 4.222 \\
$\delta < 1.25$   & 0.0\% \\
\midrule
Near (0.3--1.0m)  & 3.043 m \\
Mid (1.0--2.0m)   & 5.563 m \\
Far (2.0--4.0m)   & 7.211 m \\
\midrule
Prediction range  & 0.500 -- 59.252 m \\
Mean latency      & 81 ms (12.4 FPS on L40S) \\
\bottomrule
\end{tabular}
\end{table}

\textbf{The metric conversion formula completely fails on the Femto Bolt
camera.} Predictions reach 59\,m in a corridor where nothing is beyond
3\,m. This is \emph{worse} than the student models (2.4--2.8\,m).

\subsubsection{Root Cause: Focal Length / Resolution Mismatch}

The formula $d_{\text{metric}} = f \cdot d_{\text{raw}} / 300$ was
calibrated during DA3METRIC training with cameras whose focal lengths
and resolutions produce a specific ratio $f/300$. For NYU ($640 \times 480$,
$f = 519$): ratio $= 1.73$. For the Femto Bolt ($1280 \times 720$,
$f = 748$): ratio $= 2.49$.

DA3 internally resizes the input image to its processing resolution
(e.g.\ $504 \times 280$). The effective focal length at this resolution
would be $748 \times (504/1280) = 294.5$, giving ratio
$294.5/300 = 0.98$---close to identity. But the formula uses the
\emph{original} focal length (748), producing predictions $2.49\times$
too large.

For NYU, the same issue exists but the error is smaller
($1.73 \times$ vs $1.36 \times$), which was masked by NYU's wider depth
range. The Femto Bolt's higher resolution amplifies the miscalibration.

\textbf{This also partially explains the student corridor failure:} the
students were trained on DA3METRIC-LARGE depth predictions generated
on NYU images (with NYU's focal length). When evaluated on corridor
images (with the Femto Bolt's different focal length), the learned
depth scale does not transfer.

\subsubsection{Results: DA3METRIC-LARGE (Median-Scaled)}

Running DA3METRIC-LARGE in median-scaled mode bypasses the broken
focal conversion and isolates the model's underlying depth quality.

\begin{table}[h]
\centering
\caption{DA3METRIC-LARGE on corridor --- median-scaled (bypassing focal conversion)}
\label{tab:iter9-metric-large-median}
\begin{tabular}{lr}
\toprule
\textbf{Metric} & \textbf{Value} \\
\midrule
Overall RMSE      & \textcolor{improved}{\textbf{0.586 m}} \\
MAE               & 0.293 m \\
AbsRel            & 0.218 \\
$\delta < 1.25$   & 60.0\% \\
\midrule
Near (0.3--1.0m)  & 0.192 m \\
Mid (1.0--2.0m)   & 0.561 m \\
Far (2.0--4.0m)   & 1.282 m \\
\midrule
Floor             & \textcolor{improved}{\textbf{0.082 m}} \\
Walls/ceiling     & 0.703 m \\
\midrule
Mean latency      & 91 ms (11.0 FPS on L40S) \\
\bottomrule
\end{tabular}
\end{table}

\textbf{This confirms the issue is purely the focal conversion.}
DA3METRIC-LARGE achieves 0.586\,m RMSE with median-scaling---nearly
identical to DA3-SMALL's 0.596\,m. The 0.35B model's underlying depth
quality is no better than the 34.3M model's in this corridor environment.

\subsubsection{Results: DA3-SMALL (Relative + Median-Scaled)}

\begin{table}[h]
\centering
\caption{DA3-SMALL on corridor --- median-scaled relative depth}
\label{tab:iter9-da3-small}
\begin{tabular}{lr}
\toprule
\textbf{Metric} & \textbf{Value} \\
\midrule
Overall RMSE      & 0.596 m \\
MAE               & 0.301 m \\
AbsRel            & 0.221 \\
$\delta < 1.25$   & 56.1\% \\
\midrule
Near (0.3--1.0m)  & \textcolor{improved}{\textbf{0.158 m}} \\
Mid (1.0--2.0m)   & 0.486 m \\
Far (2.0--4.0m)   & 1.320 m \\
\midrule
Floor             & 0.089 m \\
Walls/ceiling     & 0.715 m \\
\midrule
Mean latency      & 73 ms (13.8 FPS on L40S) \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Comparative Analysis: All Three Modes}

\begin{table}[h]
\centering
\caption{DA3 corridor evaluation: all three configurations}
\label{tab:iter9-all}
\begin{tabular}{llrrrrrr}
\toprule
\textbf{Model} & \textbf{Mode} & \textbf{RMSE} & \textbf{Near} & \textbf{Mid} & \textbf{Far} & \textbf{Floor} & \textbf{$\delta$\textless 1.25} \\
\midrule
DA3METRIC-LARGE & Metric    & \textcolor{regression}{4.302} & 3.043 & 5.563 & 7.211 & 1.656 & 0.0\% \\
DA3METRIC-LARGE & Median    & \textcolor{improved}{0.586}  & 0.192 & 0.561 & 1.282 & 0.082 & 60.0\% \\
DA3-SMALL       & Median    & 0.596 & \textcolor{improved}{0.158} & \textcolor{improved}{0.486} & 1.320 & 0.089 & 56.1\% \\
\midrule
Student B2      & ---       & 2.356 & 2.538 & 2.379 & 1.233 & 2.420 & 5.1\% \\
Student B1      & ---       & 2.777 & 2.922 & 2.936 & 1.982 & 2.723 & 2.3\% \\
\bottomrule
\multicolumn{8}{l}{\footnotesize All RMSE values in metres. Near = 0.3--1.0\,m, Mid = 1.0--2.0\,m, Far = 2.0--4.0\,m.}
\end{tabular}
\end{table}

\textbf{Key observations:}

\begin{enumerate}[nosep]
  \item \textbf{Focal conversion is the sole cause of DA3METRIC-LARGE's
    failure.} Median-scaling reduces RMSE from 4.30\,m to 0.59\,m ---
    a $7.3\times$ improvement --- by simply bypassing the
    $f \cdot d / 300$ formula.

  \item \textbf{DA3-SMALL matches DA3METRIC-LARGE when scale is removed.}
    Overall RMSE: 0.596 vs 0.586\,m. The 10$\times$ parameter
    difference (34.3M vs 350M) provides negligible benefit in this
    geometrically simple corridor. DA3-SMALL is the correct choice
    for Jetson deployment.

  \item \textbf{DA3-SMALL is slightly better at near-range.}
    Near RMSE: 0.158\,m (SMALL) vs 0.192\,m (LARGE). The smaller
    model edges out the larger one in the collision avoidance zone.

  \item \textbf{DA3METRIC-LARGE wins on floor and $\delta < 1.25$.}
    Floor: 0.082 vs 0.089\,m. $\delta < 1.25$: 60.0\% vs 56.1\%.
    Marginal improvements from the larger model.

  \item \textbf{Both DA3 models are $\sim$4--5$\times$ better than
    distilled students.} The distillation gap is dominated by domain
    shift and metric scale mismatch, not model capacity.
\end{enumerate}

\textbf{Navigation viability:} With 0.8\,m clearance per side, the
near-range accuracy of both DA3 models ($\pm$16--19\,cm) is safe for
corridor obstacle avoidance. DA3-SMALL with one-time calibration on
the Jetson is the recommended deployment path.

\subsubsection{Distillation Gap Quantified}

\begin{table}[h]
\centering
\caption{Corridor depth: DA3 teachers vs distilled students}
\label{tab:iter9-gap}
\begin{tabular}{lrrrr}
\toprule
\textbf{Model} & \textbf{Params} & \textbf{Overall RMSE} & \textbf{Near RMSE} & \textbf{Floor RMSE} \\
\midrule
DA3METRIC-LARGE (median) & 350M   & \textcolor{improved}{\textbf{0.586 m}} & 0.192 m & \textcolor{improved}{\textbf{0.082 m}} \\
DA3-SMALL (median)       & 34.3M  & 0.596 m & \textcolor{improved}{\textbf{0.158 m}} & 0.089 m \\
Student B2 (Iter 7b)     & 15.76M & 2.356 m & 2.538 m & 2.420 m \\
Student B1 (Iter 6)      & 5.31M  & 2.777 m & 2.922 m & 2.723 m \\
\bottomrule
\end{tabular}
\end{table}

The distilled students are \textbf{4--5$\times$ worse} than DA3-SMALL
on corridor depth. The distillation process loses far more accuracy
than the parameter reduction ($34.3 \to 5.31$M, $6.5\times$ smaller)
would predict. Contributing factors:
\begin{enumerate}[nosep]
  \item \textbf{Domain shift:} Students trained on NYU (cluttered rooms)
    evaluated on corridors (simple geometry, different depth distribution).
  \item \textbf{Metric scale mismatch:} DA3METRIC-LARGE's focal-based
    conversion produces systematically biased depth on non-NYU cameras.
    Students learned this biased scale.
  \item \textbf{Multi-task interference:} Joint depth+seg training
    degraded depth quality (Iter 5 divergence analysis).
  \item \textbf{Data limitation:} 1449 NYU images provide insufficient
    diversity for the student to learn generalisable depth features.
\end{enumerate}

\subsubsection{Pipeline Changes}

\begin{itemize}[nosep]
  \item \texttt{eval\_corridor\_da3.py} (NEW): Runs DA3 directly on
    corridor frames with two modes: metric (uses $f \cdot d / 300$) and
    relative (per-frame median-scaling). Reports same metrics as
    \texttt{eval\_corridor\_depth.py} including per-bin and spatial
    breakdowns.
  \item \texttt{eval\_corridor\_da3.slurm} (NEW): SLURM script running
    DA3METRIC-LARGE (metric), DA3METRIC-LARGE (median-scaled), and
    DA3-SMALL (median-scaled) on corridor data.
\end{itemize}

\subsubsection{Implications for Deployment}

\begin{enumerate}[nosep]
  \item \textbf{Direct deployment wins:} DA3-SMALL via TensorRT on Jetson
    Orin Nano (40--50\,FPS at 308$\times$308) with a one-time scale
    calibration is the practical path. The GerdsenAI ROS2 Wrapper
    handles TensorRT export and ROS2 topic publishing.
  \item \textbf{Distillation to B1/B2 is not viable for depth} at
    current data scale. The 4--5$\times$ accuracy loss is unacceptable
    for navigation.
  \item \textbf{Segmentation distillation may still be useful:} B2
    achieved 50.2\% mIoU on NYU (best\_seg.pt). Segmentation does not
    require metric scale calibration, so domain shift is less severe.
    A seg-only student paired with direct DA3 depth is a viable hybrid
    architecture.
  \item \textbf{For the thesis:} The distillation study is a negative
    but informative result---it quantifies exactly where and why
    distillation fails for metric depth in domain-shifted settings.
    The pivot to direct deployment is a well-motivated engineering
    decision supported by the ablation data.
\end{enumerate}

\textbf{Status:} All three evaluations complete. DA3METRIC-LARGE
median-scaled confirms the issue is purely the focal conversion
(0.586\,m RMSE, matching DA3-SMALL). Direct DA3-SMALL deployment
on Jetson is the recommended path forward for depth estimation.

% ============================================================================
\section{Comparison: v1 vs v3}
\label{sec:comparison}
% ============================================================================

\begin{table}[h]
\centering
\caption{Architecture comparison: v1 (DA2 + MobileNetV3) vs v3 (DA3 + EfficientViT)}
\label{tab:arch-compare}
\begin{tabular}{lll}
\toprule
\textbf{Component} & \textbf{v1} & \textbf{v3} \\
\midrule
Student backbone   & MobileNetV3-Small      & EfficientViT-B1 \\
Parameters         & $\sim$2.5M             & 5.31M \\
Depth teacher      & DA2-Large (relative)   & DA3-Metric-Large (metric) \\
Seg teacher        & YOLO+SAM2              & YOLO+SAM2 (unchanged) \\
Depth output       & Relative (arbitrary)   & Metric (metres) \\
Conversion formula & None                   & $f \cdot d_{\text{raw}} / 300$ \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[h]
\centering
\caption{Best results per task across all experiments (per-task checkpoints)}
\label{tab:eval-compare}
\begin{tabular}{lrrrr}
\toprule
\textbf{Metric} & \textbf{B1/NYU depth} & \textbf{B1/NYU seg} & \textbf{B2/NYU depth} & \textbf{B2/NYU seg} \\
               & \textbf{(Iter 6)} & \textbf{(Iter 6)} & \textbf{(Iter 7b)} & \textbf{(Iter 7b)} \\
\midrule
Depth RMSE     & \textcolor{improved}{\textbf{0.998 m}} & 1.833 m & 1.126 m & 1.730 m \\
MAE            & \textcolor{improved}{\textbf{0.780 m}} & 1.713 m & 0.890 m & 1.618 m \\
AbsRel         & \textcolor{improved}{\textbf{0.255}}   & 0.572   & 0.285   & 0.537 \\
$\delta<1.25$  & \textcolor{improved}{\textbf{57.9\%}}  & 13.4\%  & 49.8\%  & 15.0\% \\
\midrule
Seg mIoU       & 24.1\%  & 46.5\%  & 28.8\%  & \textcolor{improved}{\textbf{50.2\%}} \\
\bottomrule
\multicolumn{5}{l}{\footnotesize All results are pure distillation (no GT in training). Per-task best checkpoints.} \\
\multicolumn{5}{l}{\footnotesize Best depth: B1 ep 39. Best seg: B2 ep 112. B1/TUM omitted (underperformed).}
\end{tabular}
\end{table}

% ============================================================================
\section{Additional Features Implemented}
% ============================================================================

\subsection{Freeze-Encoder Flag for Corridor Fine-Tuning}

Added \texttt{-{}-freeze-encoder} flag to \texttt{train.py} for two-phase
transfer learning when corridor data is available:

\begin{lstlisting}[language=bash]
# Phase 1: freeze encoder, train decoders only (5-10 epochs)
python train.py --resume best.pt --freeze-encoder \
    --epochs 10 --lr 1e-3 --data-root corridor_data/

# Phase 2: unfreeze, end-to-end fine-tuning (100 epochs)
python train.py --resume corridor_phase1_best.pt \
    --epochs 100 --lr 1e-4 --data-root corridor_data/
\end{lstlisting}

This prevents skip connection feature drift during domain adaptation.
The optimizer only tracks trainable parameters when the encoder is frozen.

\subsection{Teacher Verification Script}

\texttt{verify\_teacher\_output.py} runs on 5 frames before the full
inference job. It checks:
\begin{itemize}[nosep]
  \item Output dtype (must be float32)
  \item Shape alignment with RGB
  \item Scale sanity (mean $< 20$m, max $< 50$m)
  \item Pearson correlation with GT depth ($r > 0.7$ OK, $r < 0.5$ abort)
  \item Visual comparison PNGs saved for inspection
\end{itemize}

Exit code 1 aborts the SLURM job, preventing wasted GPU hours on
malformed teacher output.

% ============================================================================
\section{Future Work}
\label{sec:future}
% ============================================================================

Revised based on Iterations 7, 7b, 8, and 9 experimental results.

\subsection{Lessons Learned}

\begin{enumerate}
  \item \textbf{Temporal video data $\neq$ more unique data.}
    TUM RGB-D (5316 frames from 3 sequences at 30\,fps) performed
    \emph{worse} than NYU (1449 independent images) because consecutive
    frames are near-identical. Frame count is not diversity count.

  \item \textbf{Backbone scaling is task-dependent.}
    B2 (15.8M) improved segmentation ($+3.7$pp mIoU) but worsened
    depth ($+13\%$ RMSE) on the same data. More parameters help
    classification but hurt regression when data is limited.

  \item \textbf{Kendall uncertainty weighting is unstable.}
    The $\log \sigma^2$ blow-up appeared in all three experiments,
    earliest on TUM (epoch 28), then B2/NYU (epoch 92), then B1/NYU
    (epoch 115). The formulation needs clamping or replacement.

  \item \textbf{Metric depth distillation does not transfer across cameras.}
    DA3METRIC-LARGE's focal-based conversion ($f \cdot d / 300$) is
    calibrated for its training camera distribution. Applying it to the
    Femto Bolt ($f = 748$ at $1280 \times 720$) produces 4.3\,m RMSE.
    Students trained on these predictions inherit the camera-specific
    bias and fail on new cameras.

  \item \textbf{Domain shift dominates distillation loss.}
    Students trained on NYU (cluttered rooms, $0.5$--$10$\,m depth)
    produce 2.4--2.8\,m RMSE on corridors ($0.3$--$3$\,m depth).
    The distillation gap (4--5$\times$ vs DA3-SMALL) far exceeds
    what parameter reduction alone would predict.

  \item \textbf{Relative depth quality is excellent.}
    DA3-SMALL achieves 0.158\,m near-range RMSE with simple
    median-scaling---no metric conversion needed. The model's
    depth \emph{ordering} generalises across cameras and scenes;
    only the \emph{scale} requires calibration.
\end{enumerate}

\subsection{Recommended Next Steps (Priority Order)}

\subsubsection{1. Direct DA3-SMALL Deployment on Jetson (Highest Priority)}

Deploy DA3-SMALL via TensorRT on Jetson Orin Nano 8GB using the
GerdsenAI ROS2 Wrapper. Expected performance: 40--50\,FPS at
$308 \times 308$, $\sim$1.2\,GB VRAM. Requires:
\begin{itemize}[nosep]
  \item One-time scale calibration: point camera at known distance,
    compute scale factor, hardcode in the ROS2 node.
  \item YOLO alongside for object detection (0.5\,GB VRAM).
  \item Total memory budget: $\sim$6.7\,GB (fits in 8\,GB).
\end{itemize}
Setup scripts and ROS2 nodes already prepared in
\texttt{NCHSB/jetson\_deploy/}.

\subsubsection{2. Cross-Dataset DA3 Ablation (Thesis Strengthening)}

Run DA3-SMALL and DA3METRIC-LARGE on multiple indoor RGB-D datasets
and compare against sensor depth. This creates a cross-dataset ablation
table showing DA3's accuracy across environments:
\begin{itemize}[nosep]
  \item NYU Depth V2 (already have teacher data on HPC)
  \item TUM RGB-D (already have teacher data on HPC)
  \item LILocBench (hallway sequences with RealSense D455---closest
    match to deployment corridor)
  \item Corridor (459 frames, done)
\end{itemize}

\subsubsection{3. Segmentation-Only Distillation (If Time Permits)}

Distillation may still be viable for \emph{segmentation only}. B2
achieved 50.2\% mIoU on NYU. A seg-only student (no depth decoder)
paired with direct DA3 depth is a hybrid architecture worth testing.
This removes the multi-task interference that degraded depth quality.

\subsubsection{4. Corridor-Specific Training Data}

Collecting diverse corridor RGB frames (different lighting, furniture
placement, time of day) and running DA3+YOLO+SAM2 teacher inference
would provide domain-specific training data. Combined with scale-aware
loss (using known corridor geometry), this could make distillation
viable for corridors specifically.

% ============================================================================
\section{Known Issues and Next Steps}
\label{sec:next}
% ============================================================================

\begin{enumerate}
  \item \textbf{Distillation fails for corridor depth (CRITICAL):}
    Student models (B1: 2.78\,m, B2: 2.36\,m RMSE) are unusable in
    the corridor, while DA3-SMALL achieves 0.60\,m (0.16\,m near-range)
    with simple median-scaling. The 4--5$\times$ gap is caused by
    domain shift (NYU $\to$ corridor), metric scale mismatch, and
    multi-task interference. \textbf{Decision:} pivot to direct
    DA3-SMALL deployment on Jetson for depth; retain seg distillation.

  \item \textbf{DA3METRIC focal conversion is camera-dependent:}
    The $f \cdot d_{\text{raw}} / 300$ formula produces 4.3\,m RMSE
    on Femto Bolt images ($f = 748$) despite achieving 0.25\,m on NYU
    ($f = 519$). The formula is calibrated for cameras in DA3's training
    distribution and does not generalise to higher-resolution cameras.
    This also means student models trained on DA3METRIC depth learn
    camera-specific scale that does not transfer.

  \item \textbf{Multi-task divergence (partially solved):} Per-task
    checkpointing captures both optima: depth at epoch 39, seg at epoch
    152. Uncertainty weighting helped seg (46.5\% $\to$ 50.2\% with B2)
    but not depth.

  \item \textbf{Negative train loss (Iters 6, 7, 7b):} Kendall
    uncertainty $\log \sigma^2$ grows unbounded. Appeared in all
    experiments: epoch 28 (TUM), 92 (B2/NYU), 115 (B1/NYU).

  \item \textbf{Sensor failure in corridors:} 77\% of Femto Bolt
    depth pixels are dead (zero readings) due to reflective floors and
    specular surfaces. This confirms monocular depth estimation is
    essential---the ToF sensor alone cannot provide dense depth.

  \item \textbf{Backbone--task mismatch:} B2 improves seg but worsens
    depth. Optimal architecture differs by task.

  \item \textbf{Jetson deployment:} DA3-SMALL via TensorRT
    (GerdsenAI Wrapper, 40--50\,FPS on Orin Nano 8GB) with one-time
    scale calibration is the recommended path. ONNX build in progress
    on Jetson. The \texttt{NCHSB/jetson\_deploy/} folder contains
    setup scripts, YOLO ROS2 node, and launch file.
\end{enumerate}

% ============================================================================
\section{File Change Summary}
\label{sec:files}
% ============================================================================

\begin{longtable}{lp{8cm}}
\toprule
\textbf{File} & \textbf{Change} \\
\midrule
\endfirsthead
\toprule
\textbf{File} & \textbf{Change} \\
\midrule
\endhead
\texttt{config.py}             & Rewritten: EfficientViT-B1 backbone, DA3 model ID, NYU intrinsics, da2$\to$da3 field renames \\
\texttt{models/student.py}     & Rewritten: \texttt{timm} EfficientViT-B1 encoder, decoder channels from \texttt{print\_model\_shapes.py} \\
\texttt{models/losses.py}      & da2$\to$da3 renames; Iter 5: pure distillation; Iter 6: uncertainty weighting \\
\texttt{models/student.py}     & Iter 7b: \texttt{build\_student()} accepts \texttt{backbone} param, auto-adapts channels \\
\texttt{train.py}              & da2$\to$da3 renames, \texttt{-{}-freeze-encoder}; Iter 6: \texttt{-{}-uncertainty-weighting}; Iter 7: \texttt{-{}-dataset}; Iter 7b: \texttt{-{}-backbone} \\
\texttt{train.slurm}           & Added \texttt{-{}-manifest}, l40s\_public partition, torch\_pr\_742\_general account \\
\texttt{dataset/nyu\_loader.py}  & da2$\to$da3 renames, manifest path fix; Iter 5: manifest coverage print, GT fallback warning \\
\texttt{dataset/tum\_loader.py}      & NEW: TUM RGB-D loader with same dict interface as NYU/corridor \\
\texttt{dataset/corridor\_loader.py} & da2$\to$da3 renames in docstrings and dict keys \\
\texttt{teacher\_infer/run\_da3.py}  & NEW: DA3-Metric-Large inference with focal conversion and output resize \\
\texttt{teacher\_infer/run\_da2.py}  & DELETED \\
\texttt{teacher\_infer/verify\_teacher\_output.py} & NEW: pre-inference validation (shape, dtype, scale, Pearson $r$) \\
\texttt{teacher\_infer/prep\_tum.py}  & NEW: Extract TUM RGB-D sequences to flat layout (timestamp assoc, depth conversion, split) \\
\texttt{teacher\_infer/teacher\_infer\_tum.slurm} & NEW: SLURM script for TUM teacher inference (DA3 + YOLO + SAM2) \\
\texttt{teacher\_infer/run\_sam2.py} & Documentation-only: updated docstrings for 4-step pipeline description \\
\texttt{teacher\_infer/build\_manifest.py} & da2$\to$da3 field handling \\
\texttt{teacher\_infer/teacher\_infer.slurm} & DA3 steps, verify script; Iter 5: all 1449 images (not just val) \\
\texttt{train\_iter6.slurm}     & NEW: separate SLURM script for Iter 6 (\texttt{checkpoints\_iter6/}, \texttt{runs\_iter6/}) \\
\texttt{train\_iter7.slurm}     & NEW: TUM training with \texttt{-{}-dataset tum}, uncertainty weighting \\
\texttt{train\_iter7b\_b2.slurm} & NEW: EfficientViT-B2 on NYU (backbone comparison) \\
\texttt{eval\_distillation.py}  & DA3 metrics, fixed checkpoint loading; Iter 7b: \texttt{-{}-backbone} flag \\
\texttt{print\_model\_shapes.py} & Rewritten for EfficientViT-B1 feature inspection \\
\texttt{setup\_hpc.sh}         & anaconda3/2025.06, DA3 source install, timm, SAM2 checkpoint download \\
\texttt{requirements.txt}      & Added \texttt{timm} \\
\texttt{README.md}             & Complete rewrite for v3 architecture \\
\texttt{teacher\_infer/extract\_corridor\_bag.py} & NEW: Extract RGB+depth from Orbbec Femto Bolt MCAP rosbags with 3D reprojection for depth alignment \\
\texttt{eval\_corridor\_depth.py} & NEW: Depth-only eval against sensor depth with per-bin and spatial breakdown \\
\texttt{eval\_corridor.slurm}  & NEW: SLURM script for corridor depth evaluation (B1 + B2) \\
\texttt{eval\_corridor\_da3.py} & NEW: Run DA3 directly on corridor frames; supports metric and relative (median-scaled) modes \\
\texttt{eval\_corridor\_da3.slurm} & NEW: SLURM script for DA3METRIC-LARGE + DA3-SMALL corridor evaluation \\
\texttt{NCHSB/jetson\_deploy/README.md}       & NEW: Jetson Orin Nano deployment guide (DA3-Small + YOLO via TensorRT) \\
\texttt{NCHSB/jetson\_deploy/setup\_jetson.sh} & NEW: One-time Jetson setup script (clone DA3 wrapper, export YOLO engine) \\
\texttt{NCHSB/jetson\_deploy/yolo\_node.py}    & NEW: ROS2 node for YOLOv8-nano TensorRT detection \\
\texttt{NCHSB/jetson\_deploy/perception.launch.py} & NEW: ROS2 launch file for DA3 + YOLO perception stack \\
\bottomrule
\end{longtable}

% ============================================================================
\section{Timeline}
% ============================================================================

\begin{longtable}{lp{10cm}}
\toprule
\textbf{Date} & \textbf{Milestone} \\
\midrule
\endfirsthead
Feb 2026 & Initial pipeline design: DA2 + MobileNetV3-Small \\
Feb 2026 & HPC environment setup (resolved anaconda, SLURM, conda TOS issues) \\
Feb 2026 & v1 teacher inference (DA2 + SAM2) --- multiple SAM2 issues fixed \\
Feb 2026 & v1 training complete (100 epochs, best RMSE 1.11m vs NYU GT) \\
Feb 2026 & v1 eval reveals depth RMSE 75.37m vs DA2 --- scale mismatch identified \\
Feb 2026 & Decision: switch to DA3-Metric-Large + EfficientViT-B1 \\
Feb 2026 & v3 plan finalized with external review (Claude, ChatGPT) \\
Feb 2026 & Branch \texttt{v3-da3-efficientvit} created, full codebase rewrite \\
Feb 2026 & DA3 verification passed (Pearson $r > 0.85$ on all 5 frames) \\
Feb 2026 & v3 teacher inference complete (290/290, DA3 at 17 FPS on L40S) \\
Feb 2026 & v3 Iter 1 training: RMSE 1.05m vs DA3 (no manifest bug) \\
Feb 2026 & Fixed: checkpoint loading, manifest path resolution \\
Feb 2026 & v3 Iter 2 training: RMSE 1.07m vs DA3 (manifest used but confidence masks DA3 out) \\
Feb 27, 2026 & v3 Iter 2 eval: RMSE 1.00m, AbsRel 0.238, mIoU 19.2\% \\
Feb 27, 2026 & Iter 3: pure DA3+SAM2 distillation --- regressed (RMSE 1.13m) \\
Feb 27, 2026 & Root cause: DA3 noisier than NYU GT; pure distillation unstable \\
Feb 27, 2026 & Blended loss (gt\_blend) rejected --- GT must not be in training loss \\
Feb 28, 2026 & Iter 4: pure distillation, LR $3 \times 10^{-4}$, 200 epochs (overfitting) \\
Feb 28, 2026 & Root cause found: teacher inference only covered 290/1449 images \\
Feb 28, 2026 & Iter 5: full-dataset teachers (all 1449), pure distillation \\
Feb 28, 2026 & Iter 5 training complete (200 epochs): depth/seg divergence observed \\
Feb 28, 2026 & Iter 5 eval: RMSE 0.993m, mIoU 30.0\% (first pure distillation) \\
Feb 28, 2026 & Iter 6: uncertainty weighting + per-task checkpoints \\
Feb 28, 2026 & Iter 6 eval: depth RMSE 0.998m (best\_depth), seg mIoU 46.5\% (best\_seg) \\
Feb 28, 2026 & Iter 7: TUM RGB-D integration (prep script, loader, teacher SLURM, train SLURM) \\
Feb 28, 2026 & Iter 7b: EfficientViT-B2 backbone experiment on NYU (code ready) \\
Feb 28, 2026 & Iter 7 training complete: B1/TUM underperforms B1/NYU (temporal redundancy) \\
Feb 28, 2026 & Iter 7b training + eval complete: B2 seg 50.2\% mIoU ($+3.7$pp), depth worse \\
Feb 28, 2026 & Diagnosis: video data $\neq$ diverse data; Kendall unstable in all experiments \\
Feb 28, 2026 & Iter 8: Corridor eval pipeline (extract 459 frames from Femto Bolt rosbag) \\
Feb 28, 2026 & Iter 8: 3D depth reprojection implemented (depth optical $\to$ color optical frame) \\
Feb 28, 2026 & Iter 8 results: B1 RMSE 2.78\,m, B2 RMSE 2.36\,m --- students unusable in corridor \\
Feb 28, 2026 & Created \texttt{NCHSB/jetson\_deploy/} for direct DA3-Small + YOLO Jetson deployment \\
Mar 1, 2026  & Iter 9: DA3 direct corridor evaluation (discovered DA3METRIC-SMALL does not exist) \\
Mar 1, 2026  & Iter 9: DA3METRIC-LARGE metric conversion fails on Femto Bolt (RMSE 4.30\,m) \\
Mar 1, 2026  & Iter 9: DA3-SMALL with median-scaling achieves 0.60\,m RMSE (0.16\,m near-range) \\
Mar 1, 2026  & \textbf{Key decision:} direct DA3-SMALL on Jetson is viable; distillation not viable for depth \\
\bottomrule
\end{longtable}

% ============================================================================
\section{Vivek's HPC Run Log}
\label{sec:vivek-hpc}
% ============================================================================

This section documents the experiments conducted by Vivek Menon (vm2677) on the
NYU Torch HPC cluster, building on the pipeline established in Iterations 1--8
above. All experiments use NYU Depth V2 (1449 images) with DA3 teacher labels
and pure distillation (no GT in training loss).

% ----------------------------------------------------------------------------
\subsection{Kendall v2 Clamping Fix}
\label{sec:vivek-kendall}
% ----------------------------------------------------------------------------

Nishant's Iterations 6--7b identified Kendall uncertainty weighting instability
as the root cause of training collapse: $\log \sigma^2$ grows unbounded,
producing negative train loss and task divergence. Following the recommendation
in Section~\ref{sec:future}, the fix was applied.

\subsubsection{Change}

In \texttt{models/losses.py}, the learned log-variance parameters were clamped
before use in the loss computation:

\begin{lstlisting}[language=Python]
# Before (unstable):
precision_d = torch.exp(-self.log_var_depth)
loss = precision_d * depth_loss + self.log_var_depth + ...

# After (clamped to [-4, 4]):
log_var_d = self.log_var_depth.clamp(-4, 4)
precision_d = torch.exp(-log_var_d)
loss = precision_d * depth_loss + log_var_d + ...
\end{lstlisting}

This bounds the effective task weight to $[e^{-4}, e^{4}] \approx [0.018, 54.6]$,
preventing the variance blow-up that appeared at epoch 28 (TUM), 92 (B2/NYU),
and 115 (B1/NYU) in prior experiments.

\subsubsection{Result}

Training no longer exhibits negative loss or task weight divergence. The
$\log \sigma^2$ values stay within the clamp bounds throughout all 200 epochs.
This fix was applied to all subsequent experiments.

% ----------------------------------------------------------------------------
\subsection{Fixed-Weight Experiment}
\label{sec:vivek-fixed-weight}
% ----------------------------------------------------------------------------

As a control experiment, Kendall uncertainty weighting was replaced with fixed
equal weights ($w_d = w_s = 1.0$) to test whether the adaptive weighting
mechanism was helping at all.

\subsubsection{Result}

\textbf{Catastrophic failure.} Without adaptive weighting, the depth and
segmentation gradients compete destructively. The segmentation loss (cross-entropy)
dominates early training due to its larger gradient magnitude, starving the depth
decoder of learning signal. Both tasks converged to poor optima.

\textbf{Conclusion:} Kendall weighting with clamping is strictly better than
fixed weights. The adaptive mechanism is needed; only the unbounded variance
was problematic.

% ----------------------------------------------------------------------------
\subsection{V3: MobileNetV3-Small with Training Optimizations}
\label{sec:vivek-v3}
% ----------------------------------------------------------------------------

Applied four training optimizations to the MobileNetV3-Small backbone
($\sim$1.5M parameters) used in Nishant's original v1 pipeline:

\subsubsection{Optimizations Applied}

\begin{enumerate}[nosep]
  \item \textbf{ImageNet normalization in the model:} Moved
    $\text{mean} = [0.485, 0.456, 0.406]$, $\text{std} = [0.229, 0.224, 0.225]$
    normalization into the model's \texttt{forward()} method as registered
    buffers. This ensures consistent normalization at both training and
    inference time (previously applied inconsistently in the dataloader).

  \item \textbf{berHu loss for depth:} Replaced L1 depth loss with reverse
    Huber (berHu) loss:
    \[
      \mathcal{L}_{\text{berHu}}(e) =
      \begin{cases}
        |e| & \text{if } |e| \leq c \\
        \frac{e^2 + c^2}{2c} & \text{if } |e| > c
      \end{cases}
    \]
    where $c = 0.2 \cdot \max(|e|)$ is an adaptive threshold. berHu is L1 for
    small errors (robust to noise) and L2 for large errors (penalises outliers
    more aggressively), which is standard in monocular depth estimation.

  \item \textbf{Encoder/decoder LR split:} Pretrained encoder parameters
    receive $\text{LR} \times 0.1$ while randomly initialised decoder
    parameters receive the full learning rate. This prevents catastrophic
    forgetting of pretrained features while allowing decoders to converge
    quickly.

  \item \textbf{Encoder freeze warmup:} The encoder is frozen for the first
    5 epochs, training only the decoder heads. This allows the decoders to
    adapt to the encoder's feature distribution before fine-tuning begins.
\end{enumerate}

\subsubsection{Training Configuration}

\begin{itemize}[nosep]
  \item Backbone: MobileNetV3-Small ($\sim$1.5M params)
  \item Dataset: NYU Depth V2 (1449 images, DA3 teacher labels)
  \item Loss: berHu (depth) + cross-entropy (seg) + Kendall v2 (clamped)
  \item LR: $3 \times 10^{-4}$ (decoder), $3 \times 10^{-5}$ (encoder)
  \item Epochs: 200, batch size: 32
  \item Encoder freeze: first 5 epochs
\end{itemize}

\subsubsection{Training Results}

\begin{table}[h]
\centering
\caption{V3 (MobileNetV3-Small + optimizations): NYU GT evaluation}
\label{tab:vivek-v3-eval}
\begin{tabular}{lrr}
\toprule
\textbf{Metric} & \textbf{Best depth} & \textbf{Best seg} \\
                 & \textbf{(epoch 8)}  & \\
\midrule
Depth RMSE       & 1.16\,m             & --- \\
Seg mIoU         & ---                 & 39.3\% \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Analysis:} The optimizations fixed training stability (no more negative
loss) and modestly improved segmentation ($+8.8$pp vs pre-Kendall-fix baselines),
but depth RMSE stalled at 1.16\,m --- \emph{worse} than Nishant's Iter 5
(0.993\,m) and Iter 6 (0.998\,m). The best depth appeared very early (epoch 8),
then degraded, indicating the MobileNetV3-Small backbone lacks capacity
for the depth task on this dataset.

\textbf{Conclusion:} Training optimizations alone cannot compensate for
insufficient backbone capacity. The 1.5M-parameter MobileNetV3-Small encoder
is too small to learn both depth structure and semantic categories from 1449
images.

% ----------------------------------------------------------------------------
\subsection{V4: EfficientViT-B1 Backbone Swap}
\label{sec:vivek-v4}
% ----------------------------------------------------------------------------

Based on the V3 result showing backbone capacity as the bottleneck,
the student architecture was rewritten to use EfficientViT-B1
(\texttt{efficientvit\_b1.r224\_in1k} via \texttt{timm}), the same backbone
Nishant used in Iterations 5--8. The key difference from Nishant's experiments:
all V3 training optimizations (berHu, LR split, Kendall clamping, ImageNet
norm in model) were retained.

\subsubsection{Architecture}

\begin{itemize}[nosep]
  \item \textbf{Encoder:} EfficientViT-B1 (MIT Han Lab, ICCV 2023)
  \item \textbf{Encoder params:} 4.64M (pretrained on ImageNet-1K)
  \item \textbf{Decoder params:} 0.67M (depth + segmentation heads)
  \item \textbf{Total:} 5.31M parameters
  \item \textbf{Feature maps:} $[32, 64, 128, 256]$ channels at
    $[1/4, 1/8, 1/16, 1/32]$ spatial resolution
  \item \textbf{Skip connections:} 3 lateral connections from stages 0--2
    ($[32, 64, 128]$ channels) to U-Net-style decoders
\end{itemize}

\subsubsection{Code Changes}

\begin{itemize}[nosep]
  \item \texttt{models/student.py} --- \textbf{Major rewrite}: Made
    backbone-agnostic. \texttt{build\_student(backbone=...)} accepts any
    backbone name. Channel sizes are read dynamically from
    \texttt{timm.feature\_info.channels()}, so decoders auto-adapt to any
    EfficientViT variant (B0, B1, B2, B3) or any \texttt{timm} backbone.
    Supports both EfficientViT (via \texttt{timm}) and MobileNetV3 (via
    \texttt{torchvision}) with a unified forward pass.

  \item \texttt{config.py} --- Added \texttt{BACKBONE: str} field
    (default: \texttt{"efficientvit\_b1"}).

  \item \texttt{train.py} --- Added \texttt{-{}-backbone} CLI flag.
    Backbone name is saved in checkpoint under \texttt{ckpt["config"]["BACKBONE"]}
    for automatic detection at evaluation time.

  \item \texttt{eval\_distillation.py} --- Added \texttt{-{}-backbone} flag
    with auto-detection from checkpoint config. Falls back to
    \texttt{cfg.BACKBONE} if not stored in checkpoint.

  \item \texttt{evaluate.py} --- Auto-detects backbone from checkpoint config
    via \texttt{ckpt["config"]["BACKBONE"]}.

  \item \texttt{visualize.py} --- Auto-detects backbone from checkpoint config.

  \item \texttt{calibrate\_depth.py} --- \textbf{New script}: Computes affine
    (scale-shift) correction for student depth predictions. Measures global
    and per-image Pearson correlation to assess whether the model learns
    meaningful depth structure. Reports raw vs corrected RMSE, MAE, and
    $\delta < 1.25$. Auto-detects backbone from checkpoint.

  \item \texttt{train\_v4.slurm} --- \textbf{New}: Combined 4-stage SLURM
    pipeline: (1) train 200 epochs with \texttt{-{}-backbone efficientvit\_b1},
    (2) evaluate against NYU GT via \texttt{evaluate.py},
    (3) evaluate against DA3 teacher via \texttt{eval\_distillation.py},
    (4) depth calibration analysis via \texttt{calibrate\_depth.py}.
    All output in a single \texttt{.out} file.

  \item \texttt{requirements.txt} --- Added \texttt{timm>=0.9.0}.
\end{itemize}

\subsubsection{Training Configuration}

\begin{itemize}[nosep]
  \item Backbone: EfficientViT-B1 (5.31M params)
  \item Dataset: NYU Depth V2 (1449 images, DA3 teacher labels)
  \item Loss: berHu (depth) + cross-entropy (seg) + Kendall v2 (clamped)
  \item LR: $3 \times 10^{-4}$ (decoder), $3 \times 10^{-5}$ (encoder)
  \item Epochs: 200, batch size: 32
  \item GPU: NVIDIA L40S (48\,GB), partition \texttt{l40s\_public}
  \item SLURM job: \texttt{train\_v4.slurm} (job name: \texttt{v4-evit-b1})
\end{itemize}

\subsubsection{NYU Ground Truth Evaluation}

\begin{table}[h]
\centering
\caption{V4 (EfficientViT-B1) vs prior best results: NYU GT evaluation}
\label{tab:vivek-v4-eval}
\begin{tabular}{lrrrr}
\toprule
\textbf{Metric} & \textbf{V3 (MNv3)} & \textbf{Iter 6 (B1)} & \textbf{Iter 7b (B2)} & \textbf{V4 (B1)} \\
                 & \textbf{Vivek}      & \textbf{Nishant}     & \textbf{Nishant}      & \textbf{Vivek} \\
\midrule
Depth RMSE       & 1.160\,m & 0.998\,m & 1.126\,m & \textcolor{improved}{\textbf{0.774\,m}} \\
MAE              & ---      & 0.780\,m & 0.890\,m & \textcolor{improved}{\textbf{0.561\,m}} \\
AbsRel           & ---      & 0.255    & 0.285    & \textcolor{improved}{\textbf{0.221}} \\
$\delta < 1.25$  & ---      & 57.9\%   & 49.8\%   & \textcolor{improved}{\textbf{63.3\%}} \\
\midrule
Seg mIoU         & 39.3\%   & 46.5\%   & 50.2\%   & \textcolor{improved}{\textbf{51.0\%}} \\
\quad floor      & ---      & 63.5\%   & 67.6\%   & \textcolor{improved}{\textbf{76.8\%}} \\
\quad wall       & ---      & 16.6\%   & 22.2\%   & \textcolor{improved}{\textbf{73.0\%}} \\
\quad person     & ---      & 40.8\%   & 45.1\%   & \textcolor{regression}{26.5\%} \\
\quad furniture  & ---      & 61.2\%   & 64.6\%   & \textcolor{regression}{61.4\%} \\
\quad glass      & ---      & NaN      & NaN      & \textcolor{improved}{19.4\%} \\
\quad other      & ---      & 50.4\%   & 51.4\%   & \textcolor{regression}{48.6\%} \\
\bottomrule
\multicolumn{5}{l}{\footnotesize V4 best\_depth checkpoint (epoch 45). All results: pure distillation, no GT in training loss.} \\
\end{tabular}
\end{table}

\subsubsection{Analysis}

V4 sets \textbf{new records on every depth metric}: RMSE 0.774\,m ($-22.4\%$
vs Iter 6's 0.998\,m), MAE 0.561\,m ($-28.1\%$), AbsRel 0.221 ($-13.3\%$),
$\delta < 1.25$ at 63.3\% ($+5.4$pp). This is the first configuration where
depth RMSE drops below 0.8\,m.

Segmentation: overall mIoU 51.0\% ($+0.8$pp vs B2's 50.2\%), with a
\textbf{massive wall improvement} (73.0\% vs 22.2\%, $+50.8$pp) and
\textbf{glass detection} appearing for the first time (19.4\% vs NaN).
Floor also improved significantly (76.8\% vs 67.6\%, $+9.2$pp). Person
and furniture regressed slightly, likely due to the combined
berHu + Kendall clamping changing the loss landscape.

\textbf{Key insight:} The combination of EfficientViT-B1 backbone \emph{plus}
the V3 training optimizations (berHu, LR split, Kendall clamping) produced
results better than either approach alone. Nishant's Iter 6 (B1 without
optimizations) achieved 0.998\,m RMSE; Vivek's V3 (optimizations without B1)
achieved 1.16\,m. V4 (both together) achieved 0.774\,m --- a synergistic
improvement, not merely additive.

% ----------------------------------------------------------------------------
\subsection{Depth Calibration Analysis}
\label{sec:vivek-calibration}
% ----------------------------------------------------------------------------

To assess whether the student model learns meaningful depth \emph{structure}
(correct relative ordering) vs just predicting a constant mean, a calibration
analysis was performed using affine (scale-shift) alignment against NYU
ground truth.

\subsubsection{Method}

For all valid pixels ($d_{\text{GT}} > 0$) across the 290 validation images,
compute the least-squares affine correction:
\[
  d_{\text{corrected}} = \alpha \cdot d_{\text{pred}} + \beta
\]
where $\alpha$ (scale) and $\beta$ (shift) minimise
$\| \alpha \cdot d_{\text{pred}} + \beta - d_{\text{GT}} \|^2$.

A high Pearson correlation with GT indicates the model has learned correct
depth \emph{ordering} (near vs far), even if the absolute scale is off.
If affine correction substantially reduces RMSE, the model's depth structure
is good but needs rescaling. If correction barely helps, the model is already
well-calibrated.

\subsubsection{Results}

\begin{table}[h]
\centering
\caption{Depth calibration: V4 best\_depth.pt (epoch 45)}
\label{tab:vivek-calibration}
\begin{tabular}{lrrr}
\toprule
\textbf{Metric} & \textbf{Raw} & \textbf{After affine} & \textbf{Change} \\
\midrule
RMSE (m)         & 0.7741 & 0.7598 & $-1.8\%$ \\
MAE (m)          & 0.5613 & 0.5534 & $-1.4\%$ \\
$\delta < 1.25$  & 63.3\% & 64.4\% & $+1.1$pp \\
\bottomrule
\end{tabular}
\end{table}

\begin{itemize}[nosep]
  \item \textbf{Global Pearson correlation:} $r = 0.83$ (strong positive)
  \item \textbf{Median per-image correlation:} $r = 0.83$
  \item \textbf{Images with $r > 0.7$:} 222 / 290 (76.6\%)
  \item \textbf{Images with $r > 0.5$:} 262 / 290 (90.3\%)
  \item \textbf{Affine coefficients:} $\alpha = 0.9030$, $\beta = 0.1941$\,m
  \item \textbf{Prediction statistics:} mean = $2.574$\,m, std = $1.211$\,m,
    range $[0.024, 8.834]$\,m
  \item \textbf{GT statistics:} mean = $2.529$\,m, std = $1.203$\,m
\end{itemize}

\subsubsection{Interpretation}

\begin{enumerate}[nosep]
  \item \textbf{The model genuinely learns depth structure.} A correlation of
    0.83 means the student's depth predictions correctly order near vs far
    regions in the vast majority of images (222/290 with $r > 0.7$).

  \item \textbf{The model is already well-calibrated.} Affine correction
    only improves RMSE by 1.8\%. The scale factor $\alpha = 0.90$ and
    shift $\beta = 0.19$\,m are close to identity ($\alpha = 1.0$,
    $\beta = 0.0$), confirming that the student outputs are in approximately
    correct metric scale --- a direct consequence of using DA3-Metric-Large
    as the depth teacher.

  \item \textbf{No post-hoc rescaling needed for deployment.} The student
    can be deployed directly on the Jetson without scale-shift correction.
    The 1.8\% improvement from affine alignment is within noise margin.
\end{enumerate}

% ----------------------------------------------------------------------------
\subsection{V4 File Change Summary}
\label{sec:vivek-files}
% ----------------------------------------------------------------------------

\begin{longtable}{lp{8cm}}
\toprule
\textbf{File} & \textbf{Change} \\
\midrule
\endfirsthead
\toprule
\textbf{File} & \textbf{Change} \\
\midrule
\endhead
\texttt{models/student.py}     & Major rewrite: backbone-agnostic architecture supporting EfficientViT (via \texttt{timm}) and MobileNetV3 (via \texttt{torchvision}). Channel sizes auto-discovered from \texttt{timm.feature\_info}. ImageNet normalization as registered buffers in \texttt{forward()}. \\
\texttt{models/losses.py}      & Kendall v2 clamping: $\log \sigma^2$ clamped to $[-4, 4]$. berHu depth loss added. \\
\texttt{config.py}             & Added \texttt{BACKBONE: str = "efficientvit\_b1"} field. \\
\texttt{train.py}              & Added \texttt{-{}-backbone} flag. Encoder/decoder LR split ($\times 0.1$). Encoder freeze warmup. Saves backbone name in checkpoint config dict. \\
\texttt{eval\_distillation.py} & Added \texttt{-{}-backbone} flag with auto-detection from \texttt{ckpt["config"]["BACKBONE"]}. \\
\texttt{evaluate.py}           & Auto-detects backbone from checkpoint config. \\
\texttt{visualize.py}          & Auto-detects backbone from checkpoint config. \\
\texttt{calibrate\_depth.py}   & NEW: Affine (scale-shift) calibration analysis. Computes global and per-image Pearson correlation, least-squares affine correction, and $\delta < 1.25$ with corrected values. \\
\texttt{calibrate.slurm}       & NEW: SLURM script for running calibration on multiple checkpoints. \\
\texttt{train\_v4.slurm}       & NEW: Combined 4-stage SLURM pipeline (train $\to$ NYU eval $\to$ distillation eval $\to$ calibration). All output in single \texttt{.out} file. \\
\texttt{requirements.txt}      & Added \texttt{timm>=0.9.0} for EfficientViT backbone. \\
\bottomrule
\end{longtable}

% ----------------------------------------------------------------------------
\subsection{Conclusion and Status}
\label{sec:vivek-conclusion}
% ----------------------------------------------------------------------------

V4 (EfficientViT-B1 + training optimizations) is the \textbf{best single-checkpoint
result} across all experiments:

\begin{itemize}[nosep]
  \item \textbf{Depth RMSE:} 0.774\,m (previously 0.998\,m, $-22\%$)
  \item \textbf{Seg mIoU:} 51.0\% (previously 50.2\%, $+0.8$pp)
  \item \textbf{Depth structure:} correlation $r = 0.83$ with NYU GT
  \item \textbf{Key wins:} wall IoU 73\% ($+51$pp), glass IoU 19\% (first detection),
    floor IoU 77\% ($+9$pp)
\end{itemize}

This result demonstrates that the combination of (a) sufficient backbone
capacity (EfficientViT-B1, 5.31M params), (b) stable multi-task loss
(Kendall v2 with clamping), and (c) proper training protocol (berHu, LR split,
freeze warmup) is necessary and sufficient for sub-0.8\,m depth RMSE on
NYU Depth V2 via pure distillation.

\textbf{Status:} V4 training and evaluation complete. Model ready for
ONNX export and TensorRT deployment on Jetson.

\end{document}

\end{document}
